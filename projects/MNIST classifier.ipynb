{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "\n",
    "# data_loader\n",
    "img_size = 64\n",
    "transform = transforms.Compose([\n",
    "#         transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 10, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(10 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=250, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().float()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0740  0.0971 -0.0175  0.0679 -0.0049  0.1140 -0.0614 -0.0920  0.0104  0.0421\n",
       "[torch.DoubleTensor of size (1,10)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "x = np.random.randn(1,1,28,28)\n",
    "x = Variable(torch.from_numpy(x))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = F.nll_loss\n",
    "\n",
    "\n",
    "# # in your training loop:\n",
    "# output = net(input)\n",
    "# loss = criterion(output, target)\n",
    "# optimizer.zero_grad()   # zero the gradient buffers\n",
    "# loss.backward()\n",
    "# optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "[1/20] - ptime: 3.37, loss: nan\n",
      "[2/20] - ptime: 3.25, loss: nan\n",
      "[3/20] - ptime: 3.26, loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4e529c68a956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepoch_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 83\u001b[0;31m         variables, grad_variables, retain_graph, create_graph)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os, time\n",
    "train_epoch = 20\n",
    "print('training start!')\n",
    "start_time = time.time()\n",
    "for epoch in range(train_epoch):\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for x, y in train_loader:\n",
    "        x,y = Variable(x.cuda()), Variable(y.cuda())\n",
    "        output = net(x)\n",
    "        loss = criterion(output,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    print('[%d/%d] - ptime: %.2f, loss: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.1142 -0.1127  0.1549  0.0980 -0.0949\n",
       "  -0.0564  0.1106 -0.0915  0.1552 -0.0260\n",
       "  -0.1157  0.1807  0.0523 -0.1858 -0.1594\n",
       "   0.1828 -0.1434  0.0024 -0.1579 -0.0143\n",
       "  -0.0889  0.1193  0.1695 -0.1254  0.0612\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.1500  0.0311 -0.0691  0.0558  0.0506\n",
       "   0.0522 -0.0571  0.0384 -0.1067  0.1101\n",
       "  -0.1783  0.0162 -0.0759 -0.1376 -0.1218\n",
       "   0.0526 -0.1895 -0.0430 -0.1406 -0.1449\n",
       "  -0.1483 -0.1761  0.1565  0.1516 -0.0942\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.1552  0.1308 -0.1287  0.1107  0.0552\n",
       "   0.1536 -0.0190 -0.1319  0.1729 -0.1083\n",
       "  -0.0777 -0.1950  0.1829 -0.1572  0.0569\n",
       "   0.0093 -0.0777 -0.1810  0.0573  0.1508\n",
       "  -0.0238 -0.1650  0.1413 -0.0412 -0.0452\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "  -0.1334  0.1595 -0.1003 -0.0029  0.0489\n",
       "  -0.1970 -0.1474 -0.0739  0.1113 -0.0142\n",
       "  -0.1154 -0.0462  0.0592 -0.0069  0.0551\n",
       "  -0.0086 -0.0472  0.0565 -0.1754 -0.0094\n",
       "  -0.1247  0.0253  0.0119  0.0068 -0.1632\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "  -0.1007 -0.0019  0.0184 -0.0335 -0.1650\n",
       "   0.0217  0.1535 -0.0960  0.1515  0.0550\n",
       "   0.1614  0.0152 -0.0304  0.0261 -0.0895\n",
       "  -0.1016  0.0380 -0.0799  0.1754 -0.0998\n",
       "   0.0193 -0.0266 -0.1136  0.0183  0.1558\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.1888  0.1485  0.1899  0.0656  0.0034\n",
       "   0.0685  0.0813 -0.0477 -0.0993  0.0164\n",
       "   0.1328  0.0771 -0.0226 -0.0175 -0.0162\n",
       "   0.0235  0.1597  0.1993  0.1198 -0.0504\n",
       "   0.1337  0.1723 -0.1695 -0.0029 -0.1386\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       "  0.0732\n",
       " -0.1233\n",
       " -0.1013\n",
       " -0.1829\n",
       " -0.1268\n",
       " -0.0704\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0188 -0.0744  0.0086\n",
       "   0.0350  0.1245 -0.1341\n",
       "   0.0918  0.1292 -0.0799\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   0.0057  0.0783 -0.0312\n",
       "   0.0571 -0.1333  0.1111\n",
       "  -0.0742  0.0367  0.1215\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "  -0.0992  0.1189  0.0126\n",
       "   0.0708  0.0075  0.0486\n",
       "  -0.1182  0.0708 -0.0251\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       "   0.0972  0.0975 -0.1249\n",
       "  -0.0577  0.0994 -0.0033\n",
       "  -0.1091 -0.0249  0.0877\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       "  -0.1197  0.0874 -0.1248\n",
       "   0.0921 -0.0185 -0.0269\n",
       "  -0.1181 -0.0281 -0.0396\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       "  -0.0051 -0.0264  0.1313\n",
       "   0.1142 -0.0761  0.1082\n",
       "   0.1203 -0.1067 -0.1105\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.1009  0.0333 -0.1332\n",
       "  -0.1231  0.1108  0.0451\n",
       "  -0.0625  0.0958  0.0706\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       "   0.0093  0.0157 -0.0818\n",
       "   0.0160  0.0757  0.1196\n",
       "  -0.0498  0.1126  0.0275\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       "  -0.0413  0.0772  0.1051\n",
       "  -0.0950 -0.0036  0.1145\n",
       "   0.0514  0.0253 -0.0364\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       "   0.1167 -0.1333 -0.0130\n",
       "  -0.0334 -0.1338 -0.0131\n",
       "  -0.1299  0.1123 -0.0645\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       "  -0.0759  0.0947 -0.0054\n",
       "  -0.0362  0.0818  0.0198\n",
       "  -0.1120 -0.0843 -0.1001\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       "  -0.0613 -0.0387  0.1256\n",
       "  -0.1166 -0.0640  0.1358\n",
       "   0.1319 -0.0816  0.1115\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.0615 -0.0286  0.0339\n",
       "  -0.1111  0.0346 -0.1354\n",
       "   0.0371 -0.0777  0.0272\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       "   0.1025 -0.0372 -0.0754\n",
       "   0.0544  0.0664  0.0426\n",
       "  -0.0054  0.0268  0.1263\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       "  -0.0482  0.0367 -0.0404\n",
       "   0.1010 -0.0854  0.0456\n",
       "   0.0963 -0.1207  0.0326\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       "   0.0612 -0.1098 -0.0897\n",
       "   0.0726  0.0566  0.1207\n",
       "   0.0909 -0.0890  0.0449\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       "   0.0141  0.0771  0.1091\n",
       "  -0.1198 -0.0886  0.0193\n",
       "  -0.0088  0.0236 -0.1161\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       "   0.0631  0.0928 -0.0846\n",
       "   0.0910  0.1257 -0.0754\n",
       "  -0.0195 -0.0287  0.1051\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.0553  0.0238  0.0343\n",
       "  -0.0697  0.0377 -0.1349\n",
       "   0.0429  0.1301  0.1310\n",
       " \n",
       " (3 ,1 ,.,.) = \n",
       "  -0.0221 -0.0943  0.0217\n",
       "   0.0884 -0.0948 -0.1075\n",
       "  -0.0556 -0.0045  0.0733\n",
       " \n",
       " (3 ,2 ,.,.) = \n",
       "   0.1352  0.0851 -0.0828\n",
       "  -0.1045 -0.0276  0.0257\n",
       "   0.0560 -0.0976  0.0890\n",
       " \n",
       " (3 ,3 ,.,.) = \n",
       "  -0.1209  0.1250  0.0896\n",
       "  -0.1180 -0.0178 -0.0189\n",
       "   0.0919  0.0687 -0.0320\n",
       " \n",
       " (3 ,4 ,.,.) = \n",
       "  -0.1323  0.0774 -0.1184\n",
       "   0.1161  0.1300 -0.0265\n",
       "   0.0214 -0.1341 -0.0344\n",
       " \n",
       " (3 ,5 ,.,.) = \n",
       "  -0.0161 -0.0515  0.1236\n",
       "  -0.0979 -0.0596 -0.0772\n",
       "   0.1112  0.0192 -0.0756\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "   0.0074  0.0203 -0.0601\n",
       "   0.0231  0.0865  0.0257\n",
       "  -0.1305  0.0935 -0.0512\n",
       " \n",
       " (4 ,1 ,.,.) = \n",
       "   0.0094 -0.0119  0.0755\n",
       "   0.1173 -0.0543  0.0550\n",
       "   0.0775 -0.0952 -0.0223\n",
       " \n",
       " (4 ,2 ,.,.) = \n",
       "  -0.0098  0.0647 -0.0267\n",
       "  -0.0170 -0.0213  0.0106\n",
       "  -0.0530 -0.0173  0.0508\n",
       " \n",
       " (4 ,3 ,.,.) = \n",
       "   0.0097  0.1066  0.0519\n",
       "  -0.0053  0.0346  0.0482\n",
       "   0.1353 -0.0797 -0.0049\n",
       " \n",
       " (4 ,4 ,.,.) = \n",
       "  -0.0415  0.0889  0.0116\n",
       "  -0.0134  0.0858  0.0567\n",
       "   0.0658 -0.0855 -0.0633\n",
       " \n",
       " (4 ,5 ,.,.) = \n",
       "   0.0273  0.0789  0.1066\n",
       "  -0.0294  0.0264  0.0075\n",
       "   0.0248  0.0480  0.0026\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "   0.1137  0.1205  0.1062\n",
       "  -0.0022 -0.1037  0.0216\n",
       "  -0.0027  0.0773 -0.1159\n",
       " \n",
       " (5 ,1 ,.,.) = \n",
       "   0.0720 -0.1348  0.0965\n",
       "   0.1063 -0.0519  0.0322\n",
       "   0.1202  0.0977  0.1058\n",
       " \n",
       " (5 ,2 ,.,.) = \n",
       "   0.0575  0.0126 -0.0206\n",
       "   0.0789 -0.1142  0.1032\n",
       "  -0.1325 -0.0163  0.1225\n",
       " \n",
       " (5 ,3 ,.,.) = \n",
       "  -0.0770 -0.0529 -0.0566\n",
       "  -0.1238 -0.0477 -0.0141\n",
       "  -0.0231  0.0454  0.0350\n",
       " \n",
       " (5 ,4 ,.,.) = \n",
       "  -0.0890  0.0813 -0.0761\n",
       "   0.1043 -0.0526  0.1072\n",
       "   0.0148 -0.0429 -0.0310\n",
       " \n",
       " (5 ,5 ,.,.) = \n",
       "  -0.0134  0.1225  0.1027\n",
       "   0.0551  0.0229  0.0256\n",
       "  -0.1310  0.1246  0.0416\n",
       " \n",
       " (6 ,0 ,.,.) = \n",
       "   0.0736 -0.1240  0.1272\n",
       "  -0.0142  0.1086 -0.1274\n",
       "  -0.1125 -0.0532  0.0028\n",
       " \n",
       " (6 ,1 ,.,.) = \n",
       "   0.0936 -0.0536 -0.1137\n",
       "   0.0901 -0.1127 -0.0842\n",
       "  -0.1098 -0.0637  0.0170\n",
       " \n",
       " (6 ,2 ,.,.) = \n",
       "   0.1337  0.0317  0.0415\n",
       "  -0.1297  0.0575  0.1137\n",
       "  -0.0487  0.0307 -0.1207\n",
       " \n",
       " (6 ,3 ,.,.) = \n",
       "   0.1004 -0.0524 -0.1214\n",
       "   0.1120  0.0028 -0.0397\n",
       "  -0.0353 -0.0957  0.0969\n",
       " \n",
       " (6 ,4 ,.,.) = \n",
       "   0.0098 -0.0130  0.1014\n",
       "   0.1267 -0.0534 -0.1336\n",
       "  -0.1323 -0.0986  0.0541\n",
       " \n",
       " (6 ,5 ,.,.) = \n",
       "  -0.0246  0.0228 -0.1222\n",
       "  -0.0297  0.0141 -0.0416\n",
       "   0.0464 -0.1196  0.0965\n",
       " \n",
       " (7 ,0 ,.,.) = \n",
       "   0.0529  0.0333  0.0691\n",
       "   0.1116 -0.0871 -0.0312\n",
       "   0.1302 -0.0387 -0.1132\n",
       " \n",
       " (7 ,1 ,.,.) = \n",
       "   0.0678 -0.0490  0.0462\n",
       "  -0.1120 -0.0748 -0.0434\n",
       "  -0.1142  0.0521  0.0056\n",
       " \n",
       " (7 ,2 ,.,.) = \n",
       "   0.0110  0.0085  0.0191\n",
       "   0.0971  0.0675  0.0018\n",
       "   0.1081  0.1110  0.0361\n",
       " \n",
       " (7 ,3 ,.,.) = \n",
       "   0.1263 -0.0231 -0.0872\n",
       "   0.0495  0.1315  0.0947\n",
       "  -0.0919  0.1048  0.0068\n",
       " \n",
       " (7 ,4 ,.,.) = \n",
       "   0.0539 -0.0727 -0.0167\n",
       "  -0.0467  0.0871 -0.0335\n",
       "   0.0741  0.0571  0.0686\n",
       " \n",
       " (7 ,5 ,.,.) = \n",
       "  -0.1167  0.1091 -0.0532\n",
       "   0.0973  0.1338  0.0765\n",
       "  -0.1323 -0.0281 -0.0413\n",
       " \n",
       " (8 ,0 ,.,.) = \n",
       "   0.0809 -0.0465 -0.0475\n",
       "   0.0899 -0.0709 -0.0424\n",
       "  -0.0823  0.0875 -0.1235\n",
       " \n",
       " (8 ,1 ,.,.) = \n",
       "  -0.1064  0.0319 -0.0053\n",
       "  -0.0306  0.0281 -0.1160\n",
       "  -0.0424  0.1082 -0.0324\n",
       " \n",
       " (8 ,2 ,.,.) = \n",
       "  -0.0511 -0.0854 -0.1290\n",
       "   0.1054 -0.0588 -0.0776\n",
       "   0.0272  0.0601 -0.0686\n",
       " \n",
       " (8 ,3 ,.,.) = \n",
       "   0.0953  0.0922 -0.0983\n",
       "  -0.0183  0.1161 -0.0855\n",
       "  -0.0004 -0.1198 -0.0455\n",
       " \n",
       " (8 ,4 ,.,.) = \n",
       "   0.0693  0.0816 -0.0037\n",
       "  -0.0239  0.1193  0.0231\n",
       "   0.0101 -0.1019 -0.0380\n",
       " \n",
       " (8 ,5 ,.,.) = \n",
       "  -0.1325  0.0134 -0.0613\n",
       "  -0.0011  0.0437 -0.0515\n",
       "  -0.1180 -0.0818 -0.0721\n",
       " \n",
       " (9 ,0 ,.,.) = \n",
       "   0.0590  0.1271  0.1167\n",
       "   0.0393 -0.0779  0.0680\n",
       "   0.0128  0.0771  0.0350\n",
       " \n",
       " (9 ,1 ,.,.) = \n",
       "  -0.0567  0.0504 -0.0192\n",
       "  -0.0358 -0.0679 -0.0976\n",
       "  -0.1102  0.1090  0.1092\n",
       " \n",
       " (9 ,2 ,.,.) = \n",
       "   0.1027 -0.0654 -0.1117\n",
       "   0.0605 -0.0147  0.0045\n",
       "   0.1193 -0.0907 -0.0397\n",
       " \n",
       " (9 ,3 ,.,.) = \n",
       "   0.0180 -0.1192  0.0939\n",
       "   0.1033  0.0995 -0.0619\n",
       "  -0.0314 -0.0128 -0.1139\n",
       " \n",
       " (9 ,4 ,.,.) = \n",
       "  -0.0672  0.0914 -0.1063\n",
       "  -0.0677  0.1020 -0.1179\n",
       "   0.0294 -0.0969 -0.0113\n",
       " \n",
       " (9 ,5 ,.,.) = \n",
       "   0.0392 -0.0217 -0.0572\n",
       "   0.0864  0.0500  0.0893\n",
       "  -0.1263 -0.0467  0.0416\n",
       " [torch.FloatTensor of size 10x6x3x3], Parameter containing:\n",
       " -0.0912\n",
       "  0.1131\n",
       " -0.0901\n",
       " -0.1226\n",
       "  0.0878\n",
       " -0.0092\n",
       "  0.0745\n",
       " -0.0534\n",
       "  0.1194\n",
       " -0.1057\n",
       " [torch.FloatTensor of size 10], Parameter containing:\n",
       " 1.00000e-02 *\n",
       " -3.7344  2.4803  2.5881  ...  -2.8386 -6.1198 -4.4495\n",
       " -5.4209  1.8566  1.2688  ...   5.8324 -1.6392 -4.3209\n",
       "  0.5729 -4.5431 -1.8142  ...  -0.2012 -3.8374  1.7806\n",
       "           ...             ⋱             ...          \n",
       "  1.4557  1.3065 -5.4954  ...  -1.3087  2.1869  4.5481\n",
       " -5.0891  3.5405  5.7220  ...   3.9049  0.3055 -4.7013\n",
       "  4.8373  4.2095 -4.3723  ...   0.2306  4.8255  0.9307\n",
       " [torch.FloatTensor of size 120x250], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -3.0172\n",
       "   4.9441\n",
       "   2.8209\n",
       "  -3.8264\n",
       "  -4.2018\n",
       "   2.8271\n",
       "   3.9370\n",
       "  -5.4073\n",
       "   5.3604\n",
       "  -6.0139\n",
       "   0.6554\n",
       "  -4.5066\n",
       "  -5.9278\n",
       "   5.0666\n",
       "   3.9212\n",
       "  -0.4631\n",
       "   2.3093\n",
       "  -3.7083\n",
       "   4.7264\n",
       "   0.9875\n",
       "  -5.6273\n",
       "  -1.0438\n",
       "   1.6379\n",
       "   5.7170\n",
       "   5.3041\n",
       "  -6.0608\n",
       "   1.3970\n",
       "   1.4219\n",
       "   4.9070\n",
       "   2.0436\n",
       "   2.9058\n",
       "  -2.5328\n",
       "  -1.7203\n",
       "   0.9183\n",
       "  -0.0359\n",
       "   2.8981\n",
       "  -0.1366\n",
       "  -1.2941\n",
       "   0.4637\n",
       "  -0.5604\n",
       "  -0.4547\n",
       "  -4.2472\n",
       "  -5.7266\n",
       "   1.3853\n",
       "   3.6984\n",
       "   2.9252\n",
       "   3.1439\n",
       "  -0.7888\n",
       "  -5.2361\n",
       "  -1.1319\n",
       "   4.6408\n",
       "  -3.3999\n",
       "   0.7608\n",
       "   3.5655\n",
       "   3.0537\n",
       "   3.9629\n",
       "   5.3818\n",
       "  -5.5729\n",
       "   0.9056\n",
       "   2.6592\n",
       "   5.0281\n",
       "   3.9756\n",
       "  -0.7361\n",
       "  -0.3374\n",
       "   4.4661\n",
       "  -2.2627\n",
       "   2.2921\n",
       "  -2.6072\n",
       "  -0.3000\n",
       "  -6.1648\n",
       "  -5.3421\n",
       "   4.2523\n",
       "   1.2188\n",
       "  -5.7340\n",
       "  -1.9951\n",
       "  -2.4406\n",
       "  -2.5429\n",
       "  -3.8734\n",
       "   4.6929\n",
       "   3.6525\n",
       "  -5.4148\n",
       "  -3.0346\n",
       "   6.0216\n",
       "   3.2058\n",
       "   3.0711\n",
       "   5.9097\n",
       "  -0.0894\n",
       "  -3.6993\n",
       "   3.2769\n",
       "   6.2263\n",
       "  -2.3481\n",
       "  -4.1379\n",
       "   3.5866\n",
       "  -4.0815\n",
       "  -2.6800\n",
       "   2.1792\n",
       "  -2.9212\n",
       "   5.6239\n",
       "  -2.7828\n",
       "   0.5089\n",
       "   3.7952\n",
       "  -3.7007\n",
       "  -4.8435\n",
       "   5.8927\n",
       "   3.3547\n",
       "   3.0033\n",
       "  -3.6486\n",
       "   2.5900\n",
       "  -6.1489\n",
       "  -4.1387\n",
       "  -2.2083\n",
       "   2.5279\n",
       "   5.3986\n",
       "   4.2600\n",
       "  -1.4065\n",
       "   4.1150\n",
       "  -1.9962\n",
       "  -3.9331\n",
       "   0.1051\n",
       "   1.3646\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " -2.0740e-03 -7.3048e-02 -8.4299e-02  ...   8.8122e-02 -3.1891e-02 -2.3462e-02\n",
       "  3.8790e-02 -1.0684e-02 -1.8672e-02  ...  -6.8894e-02 -2.8554e-02 -4.9134e-02\n",
       "  5.3739e-02 -1.9577e-02 -4.4354e-02  ...  -7.9672e-02  3.2368e-02 -8.0268e-02\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.8051e-02  3.2192e-02  6.6456e-02  ...   7.4987e-02 -5.0980e-02  1.4391e-02\n",
       " -2.1810e-02 -8.6213e-02 -4.2807e-02  ...   4.4270e-02  2.2296e-02 -5.3405e-02\n",
       " -6.9578e-02  7.6103e-02 -9.3174e-03  ...  -1.5178e-02 -6.3852e-02  5.8031e-02\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -1.4898\n",
       "  -2.6092\n",
       "   2.5025\n",
       "   4.7561\n",
       "  -0.4990\n",
       "   4.5918\n",
       "  -7.0682\n",
       "  -1.9569\n",
       "  -7.0595\n",
       "   0.0979\n",
       "   8.0038\n",
       "   1.2855\n",
       "   4.1383\n",
       "  -4.5017\n",
       "   7.7143\n",
       "  -1.7388\n",
       "  -8.8458\n",
       "  -7.6409\n",
       "   4.5126\n",
       "   1.2056\n",
       "  -6.3789\n",
       "   0.7602\n",
       "  -1.1856\n",
       "   0.9477\n",
       "  -6.6612\n",
       "   3.8864\n",
       "  -5.2746\n",
       "  -1.4650\n",
       "  -7.9717\n",
       "   2.2969\n",
       "   5.0298\n",
       "   1.4081\n",
       "   9.0553\n",
       "   4.0863\n",
       "  -7.6831\n",
       "   6.0572\n",
       "   8.9254\n",
       "  -6.9514\n",
       "  -0.1303\n",
       "  -8.4252\n",
       "  -4.1122\n",
       "   8.6564\n",
       "   9.0100\n",
       "  -0.2307\n",
       "  -5.8555\n",
       "  -3.7005\n",
       "   7.9547\n",
       "   7.3278\n",
       "  -1.0162\n",
       "  -0.0295\n",
       "   0.4688\n",
       "   5.8262\n",
       "   3.5606\n",
       "  -8.0036\n",
       "   1.2219\n",
       "   8.0686\n",
       "  -1.7955\n",
       "  -8.0895\n",
       "  -2.9732\n",
       "  -2.0135\n",
       "   4.9402\n",
       "  -5.5972\n",
       "  -3.1683\n",
       "  -8.2258\n",
       "  -0.9696\n",
       "   1.1117\n",
       "  -4.6004\n",
       "   7.9545\n",
       "  -2.6304\n",
       "  -3.2993\n",
       "   2.1312\n",
       "  -4.5319\n",
       "   7.6160\n",
       "  -6.6521\n",
       "   8.6730\n",
       "   3.9863\n",
       "   0.8610\n",
       "  -6.0403\n",
       "   0.7402\n",
       "  -3.5799\n",
       "  -1.8219\n",
       "  -2.7480\n",
       "   4.3705\n",
       "   4.1842\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.1072  0.0793 -0.0800  0.0494 -0.0484 -0.0982 -0.0935 -0.0055 -0.0668 -0.0796\n",
       "  0.0669  0.0946  0.1010 -0.0332 -0.0840  0.0455  0.0324  0.0191  0.0374 -0.0349\n",
       " -0.0453 -0.0646  0.0514  0.0227  0.0888 -0.0964  0.0856  0.0262  0.0744  0.0650\n",
       "  0.0399  0.0273 -0.0191  0.0548 -0.0938  0.0436  0.0458 -0.1089 -0.0679 -0.0181\n",
       "  0.1049  0.0496 -0.0257  0.0705  0.0222 -0.0542  0.0104  0.0266  0.0846 -0.0517\n",
       "  0.0551  0.0207  0.0901 -0.0277  0.0806  0.0004 -0.0968 -0.0467  0.0339 -0.0532\n",
       " -0.0767  0.0463 -0.0351 -0.1000 -0.1058 -0.0193 -0.0352 -0.0834 -0.0604 -0.0119\n",
       "  0.1068 -0.0464  0.0659  0.0697 -0.0367 -0.0929  0.0216  0.0202  0.0724 -0.0793\n",
       " -0.0873  0.0936 -0.0092 -0.0241 -0.0241  0.0023 -0.1019  0.0508  0.0948  0.0397\n",
       "  0.0013  0.1069 -0.0281 -0.0601  0.0636 -0.0924  0.0850 -0.0926  0.0404 -0.0799\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.0953 -0.0002 -0.0177  0.0158 -0.0945 -0.0184 -0.0353 -0.0428 -0.0995  0.0273\n",
       "  0.0588 -0.0858  0.0146 -0.0686 -0.0996  0.0499 -0.0686  0.1055 -0.0426  0.0978\n",
       " -0.0932 -0.0252 -0.0016  0.0453  0.0598  0.0049 -0.0096  0.0358  0.0213  0.0496\n",
       "  0.0391 -0.0784  0.0480 -0.0908  0.0463 -0.0741  0.0368 -0.1045  0.0675  0.0357\n",
       " -0.0423  0.0370 -0.0821 -0.0504 -0.0885  0.0530 -0.0032  0.0761 -0.0562  0.0419\n",
       "  0.0396  0.0271  0.0658 -0.0421  0.0438  0.0870 -0.0033  0.0193 -0.0196  0.0379\n",
       " -0.0568  0.0548  0.0105 -0.0795  0.0910  0.0901 -0.0766 -0.0926  0.0536 -0.0122\n",
       " -0.0343 -0.0852 -0.0079 -0.0110 -0.0764 -0.0111 -0.0674  0.0248  0.0448  0.0243\n",
       " -0.0442 -0.0479 -0.0100  0.0976  0.0170 -0.0352  0.0890  0.0572 -0.0735  0.0791\n",
       " -0.0209  0.0595  0.0924  0.0777 -0.0449  0.0482 -0.0039  0.0559 -0.0700 -0.0727\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.0183 -0.0890  0.1031 -0.0530 -0.0707  0.0786 -0.0335  0.0817  0.0297 -0.0777\n",
       "  0.0276 -0.0643 -0.0804  0.0999  0.0018 -0.0657 -0.0086 -0.0524  0.0314  0.0747\n",
       "  0.0369  0.0221  0.0015 -0.0056  0.0197  0.0991 -0.0565 -0.0765 -0.0981  0.0077\n",
       " -0.0033  0.0679 -0.0030 -0.0686  0.0642  0.0377 -0.0442 -0.0064 -0.0780 -0.0484\n",
       " -0.0603 -0.0073 -0.0542 -0.0867  0.0594  0.0784 -0.0431  0.0492  0.0367 -0.0189\n",
       " -0.0169 -0.0782 -0.0510 -0.0005  0.0838 -0.0409 -0.0687  0.0230  0.1074 -0.0769\n",
       " -0.0434  0.0325 -0.0633 -0.0993  0.0809 -0.0704  0.0297 -0.0441 -0.0122 -0.0425\n",
       "  0.1048  0.0964  0.0947  0.0801  0.0103 -0.0574  0.0567  0.0510  0.0591  0.0355\n",
       " -0.1032 -0.0585  0.0896 -0.0903 -0.0680  0.0365 -0.0148  0.0168 -0.0886  0.0355\n",
       "  0.0444 -0.0060 -0.1072 -0.0844 -0.0760  0.0340 -0.0286  0.0151 -0.0009  0.0031\n",
       " \n",
       " Columns 30 to 39 \n",
       "  0.0977 -0.0860 -0.0532 -0.0558 -0.0305  0.0280 -0.0581  0.0280 -0.0378  0.0087\n",
       "  0.0855  0.0087 -0.0759  0.0913  0.0166 -0.0886  0.0609 -0.0009  0.0653  0.0412\n",
       " -0.0752  0.1009  0.0916  0.0703  0.0354  0.0150  0.0831  0.0263 -0.1002 -0.0452\n",
       "  0.0030  0.0938 -0.0164 -0.1080 -0.0189 -0.0406  0.1005 -0.0770 -0.0610  0.0491\n",
       "  0.0530  0.0114 -0.1064 -0.0157 -0.0851  0.0445  0.0272 -0.0351 -0.1032 -0.0815\n",
       " -0.0156  0.0333  0.0889  0.0028 -0.0840  0.0298 -0.1032 -0.0742  0.0703 -0.0780\n",
       "  0.0861  0.0763 -0.0015 -0.0243  0.0467  0.0283 -0.0475 -0.0667 -0.0917 -0.0724\n",
       "  0.0506 -0.0688  0.1088 -0.0607 -0.1026 -0.0704 -0.0375 -0.1044 -0.0937 -0.0889\n",
       " -0.0770 -0.0736  0.0793 -0.0067  0.0784 -0.0985  0.0562 -0.0635  0.1019  0.1068\n",
       "  0.0753  0.0206 -0.0449 -0.0122 -0.0022 -0.0036 -0.0743  0.0555  0.0426 -0.0799\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.0882 -0.0070 -0.0979 -0.0960 -0.0233  0.0138 -0.0526  0.0844 -0.0645  0.0342\n",
       " -0.0447  0.0537  0.0182 -0.1006 -0.0785  0.0727 -0.0321  0.0433 -0.0728 -0.0905\n",
       " -0.0569  0.0296  0.0003 -0.0543 -0.1050 -0.0942  0.0551  0.0799 -0.1030  0.0857\n",
       "  0.1088  0.0320 -0.0384 -0.0516 -0.1077 -0.0684 -0.0322 -0.0871  0.0954 -0.0577\n",
       "  0.0504  0.0316  0.0761  0.1064  0.0125 -0.0294  0.0911  0.0131 -0.0495  0.0783\n",
       "  0.0716 -0.0258 -0.0624 -0.0693 -0.0170 -0.0156 -0.0243 -0.0665 -0.0937  0.1074\n",
       "  0.0617 -0.0310 -0.0857  0.0202  0.0905 -0.0084  0.0772  0.0081  0.0161  0.0204\n",
       "  0.0830  0.0489 -0.0702  0.0360 -0.0551 -0.1029 -0.0691  0.0100 -0.0620  0.0827\n",
       "  0.0846 -0.0785  0.0243  0.1072 -0.0472 -0.0309 -0.0263  0.0360 -0.0547 -0.0643\n",
       "  0.0349  0.1048 -0.0677  0.0638  0.0589 -0.0086  0.1041  0.0705  0.0783  0.0330\n",
       " \n",
       " Columns 50 to 59 \n",
       "  0.0408  0.0017 -0.0271 -0.0634  0.0869 -0.1002  0.0100 -0.0382 -0.0262 -0.0084\n",
       " -0.0348 -0.0193 -0.0782 -0.0455  0.0977  0.0222 -0.0027  0.0014  0.0090  0.0438\n",
       " -0.0401 -0.1041 -0.0904 -0.0656  0.0223  0.0184 -0.0162 -0.0622 -0.0655 -0.0187\n",
       "  0.0619  0.0110  0.0141  0.0539  0.1070  0.0652  0.1012  0.1075 -0.0613  0.0329\n",
       "  0.0759 -0.1060  0.0525  0.0675 -0.0349 -0.0814  0.0087  0.0022 -0.0476 -0.0246\n",
       "  0.0251  0.0757 -0.0466  0.0585 -0.0137 -0.0101  0.0718 -0.1051  0.0693 -0.0768\n",
       "  0.0537 -0.0539  0.0319  0.0160 -0.0917  0.0176 -0.1058 -0.0493 -0.1089 -0.0484\n",
       "  0.0957  0.0983  0.0382  0.0643  0.0599 -0.1002 -0.0481  0.0676 -0.0830  0.0144\n",
       "  0.0083  0.0938  0.0772  0.0345 -0.0721  0.1066  0.0658  0.0594  0.0072  0.0900\n",
       "  0.0606  0.1062 -0.0702  0.1038 -0.0594  0.0175 -0.0321  0.0669  0.0454  0.0115\n",
       " \n",
       " Columns 60 to 69 \n",
       "  0.0198 -0.0395 -0.0518  0.0017 -0.0346  0.0255  0.1023  0.0027 -0.0511  0.0584\n",
       "  0.0979  0.0695  0.1089  0.0238 -0.1035 -0.0852  0.0918  0.0243  0.0993  0.0052\n",
       " -0.0029 -0.0761  0.0358 -0.0538  0.0100 -0.0662  0.0244  0.0379  0.0367  0.0315\n",
       " -0.0399 -0.0962  0.0946 -0.0419  0.0258 -0.0119 -0.0045 -0.0141  0.1023 -0.1065\n",
       "  0.0359 -0.0216  0.0742 -0.1003 -0.0865 -0.0185  0.0758 -0.0966 -0.0650  0.0838\n",
       " -0.0428  0.0760 -0.0430  0.0012  0.0856  0.0053  0.0319 -0.0999  0.0809  0.0549\n",
       " -0.0527 -0.0464 -0.0438 -0.0314 -0.0792 -0.0586  0.1020  0.0567 -0.0727  0.0787\n",
       "  0.0488  0.0624  0.0374  0.0622  0.0431 -0.0033  0.0641 -0.0247 -0.0503  0.0727\n",
       "  0.0757 -0.0566  0.0145  0.0169  0.0227  0.0551  0.0157 -0.0277  0.0575  0.0292\n",
       "  0.0058  0.0042  0.0750 -0.1056 -0.1046  0.0365  0.0241 -0.0567  0.0644 -0.0245\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.0985 -0.0698  0.0340  0.0496 -0.0717  0.0777  0.0049  0.0931 -0.0876 -0.0188\n",
       " -0.0168  0.0190  0.0297 -0.0876 -0.0546 -0.0859  0.0343 -0.1075  0.0870 -0.0915\n",
       "  0.0586 -0.0758 -0.0802  0.0461 -0.0471 -0.0038 -0.0075 -0.1030  0.0795  0.0689\n",
       "  0.0332  0.0475 -0.0913  0.0447  0.0068 -0.0381 -0.0222  0.0898  0.0561 -0.0795\n",
       " -0.0641  0.0774 -0.0413  0.0602 -0.0519 -0.0857  0.0490  0.0718  0.0479 -0.0039\n",
       "  0.0428  0.1075  0.0878  0.0659  0.0521 -0.0993  0.0891  0.0184 -0.0220 -0.0444\n",
       " -0.0326  0.0523 -0.0986 -0.0772  0.0924  0.0646  0.0239 -0.0008  0.0806 -0.0401\n",
       " -0.1085  0.0286  0.0377  0.0636  0.0327 -0.0631  0.0783 -0.0421  0.0936 -0.0944\n",
       " -0.0714 -0.0823 -0.0633 -0.0740  0.1020 -0.0256 -0.0343 -0.0249  0.0799  0.0718\n",
       "  0.0197 -0.0843 -0.0881  0.0721  0.0179  0.0078 -0.0913 -0.0429 -0.0361 -0.0680\n",
       " \n",
       " Columns 80 to 83 \n",
       "  0.0444  0.0702  0.0227  0.0017\n",
       " -0.0300 -0.0932 -0.0053  0.0731\n",
       "  0.0976 -0.0275  0.0505 -0.0046\n",
       "  0.0687  0.0276 -0.1081  0.0937\n",
       "  0.0909  0.0310  0.0318  0.0518\n",
       " -0.0459  0.0505  0.0641  0.0430\n",
       "  0.0997 -0.0443 -0.0646 -0.0425\n",
       " -0.0249  0.0154 -0.0461  0.0623\n",
       " -0.0581  0.1049 -0.0399 -0.0716\n",
       " -0.0883 -0.1000 -0.0261 -0.0128\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       "  0.0021\n",
       " -0.1058\n",
       "  0.0812\n",
       " -0.0722\n",
       "  0.0446\n",
       "  0.0547\n",
       "  0.0806\n",
       "  0.1001\n",
       " -0.0303\n",
       "  0.0163\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-1de833a4f56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "labels_one_hot = torch.FloatTensor(128, k, 10).zero_()\n",
    "labels_one_hot.scatter_(2, x, 1)\n",
    "labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
