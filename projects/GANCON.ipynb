{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G(z) -- GENERATOR\n",
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "fixed_z_ = torch.randn((5 * 5, 100)).view(-1, 100, 1, 1)    # fixed noise\n",
    "fixed_z_ = Variable(fixed_z_.cuda(), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(num_epoch, show = False, save = False, path = 'result.png', isFix=False):\n",
    "    z_ = torch.randn((5*5, 100)).view(-1, 100, 1, 1)\n",
    "    z_ = Variable(z_.cuda(), volatile=True)\n",
    "\n",
    "    G.eval()\n",
    "    if isFix:\n",
    "        test_images = G(fixed_z_)\n",
    "    else:\n",
    "        test_images = G(z_)\n",
    "    G.train()\n",
    "\n",
    "    size_figure_grid = 5\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i, j].get_xaxis().set_visible(False)\n",
    "        ax[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "    for k in range(5*5):\n",
    "        i = k // 5\n",
    "        j = k % 5\n",
    "        ax[i, j].cla()\n",
    "        ax[i, j].imshow(test_images[k, 0].cpu().data.numpy(), cmap='gray')\n",
    "\n",
    "    label = 'Epoch {0}'.format(num_epoch)\n",
    "    fig.text(0.5, 0.04, label, ha='center')\n",
    "    plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Iter')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "train_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# data_loader\n",
    "img_size = 64\n",
    "transform = transforms.Compose([\n",
    "        transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv4): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv5): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network\n",
    "G = generator(128)\n",
    "D = discriminator(128)\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "G.cuda()\n",
    "D.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results save folder\n",
    "if not os.path.isdir('MNIST_DCGAN_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results')\n",
    "if not os.path.isdir('MNIST_DCGAN_results/Random_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results/Random_results')\n",
    "if not os.path.isdir('MNIST_DCGAN_results/Fixed_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results/Fixed_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []\n",
    "num_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "0\n",
      "3.116257176057362 0.5683808841113088\n",
      "1\n",
      "3.4550060752961937 0.47290813111896707\n",
      "2\n",
      "3.5096890973939954 0.4977594440393865\n",
      "3\n",
      "3.409795150565885 0.5286748471147598\n",
      "4\n",
      "3.3796697952996517 0.47692563010256556\n",
      "5\n",
      "3.4436400378309586 0.4657925710495093\n",
      "6\n",
      "3.991146556473077 0.3224607467262158\n",
      "7\n",
      "3.3953603198017075 0.5501036892619247\n",
      "8\n",
      "3.754974347656406 0.42189560033110923\n",
      "9\n",
      "3.726423527896484 0.42810605948906083\n",
      "10\n",
      "3.961014992239744 0.3198930212318389\n",
      "11\n",
      "3.336749071179371 0.586820012099469\n",
      "12\n",
      "3.8496607270226804 0.3302530576544466\n",
      "13\n",
      "4.202248999877259 0.3927110215144625\n",
      "14\n",
      "3.8774321739996784 0.3972678055534008\n",
      "15\n",
      "3.745596110908144 0.38960526783519717\n"
     ]
    }
   ],
   "source": [
    "print('training start!')\n",
    "start_time = time.time()\n",
    "for epoch in range(train_epoch-4):\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for x_, _ in train_loader:\n",
    "        # train discriminator D\n",
    "        D.zero_grad()\n",
    "\n",
    "        mini_batch = x_.size()[0]\n",
    "\n",
    "        y_real_ = torch.ones(mini_batch)\n",
    "        y_fake_ = torch.zeros(mini_batch)\n",
    "\n",
    "        x_, y_real_, y_fake_ = Variable(x_.cuda()), Variable(y_real_.cuda()), Variable(y_fake_.cuda())\n",
    "        D_result = D(x_).squeeze()\n",
    "        D_real_loss = BCE_loss(D_result, y_real_)\n",
    "\n",
    "        z_ = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n",
    "        z_ = Variable(z_.cuda())\n",
    "        G_result = G(z_)\n",
    "\n",
    "        D_result = D(G_result).squeeze()\n",
    "        D_fake_loss = BCE_loss(D_result, y_fake_)\n",
    "        D_fake_score = D_result.data.mean()\n",
    "\n",
    "        D_train_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "        D_train_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # D_losses.append(D_train_loss.data[0])\n",
    "        D_losses.append(D_train_loss.data[0])\n",
    "\n",
    "        # train generator G\n",
    "        G.zero_grad()\n",
    "\n",
    "        z_ = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n",
    "        z_ = Variable(z_.cuda())\n",
    "\n",
    "        G_result = G(z_)\n",
    "        D_result = D(G_result).squeeze()\n",
    "        G_train_loss = BCE_loss(D_result, y_real_)\n",
    "        G_train_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        G_losses.append(G_train_loss.data[0])\n",
    "\n",
    "        num_iter += 1\n",
    "    \n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    print('[%d/%d] - ptime: %.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, torch.mean(torch.FloatTensor(D_losses)),\n",
    "                                                              torch.mean(torch.FloatTensor(G_losses))))\n",
    "    p = 'MNIST_DCGAN_results/Random_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "    fixed_p = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "    show_result((epoch+1), save=True, path=p, isFix=False)\n",
    "    show_result((epoch+1), save=True, path=fixed_p, isFix=True)\n",
    "    train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
    "    train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
    "    train_hist['per_epoch_ptimes'].append(per_epoch_ptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n",
    "z_ = Variable(z_.cuda())\n",
    "G_result = G(z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c700526a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c700a44e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(G_result.cpu().data.numpy()[3,0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 1, 64, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_result.cpu().data.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 10, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(10 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "import pickle\n",
    "net.load_state_dict(pickle.load(open(\"trained_mnist_classifier.pkl\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=250, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(net.parameters())\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3\n",
       "[torch.cuda.LongTensor of size (1,) (GPU 0)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.FloatTensor(RescaleTrans(Image.fromarray(G_result[0,0].cpu().mul(0.5).add(0.5).mul(255).byte().numpy())).numpy())\n",
    "input = Variable(input.cuda())\n",
    "\n",
    "_,pred = torch.max(net(torch.unsqueeze(input,0)),1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0039  0.0078  0.0039  0.0039  0.0000  0.0078  0.0039  0.0039  0.0078\n",
       "  0.0078  0.0118  0.0078  0.0118  0.0078  0.0157  0.0118  0.0078  0.0078\n",
       "  0.0078  0.0118  0.0118  0.0235  0.0235  0.0196  0.0157  0.0118  0.0078\n",
       "  0.0118  0.0118  0.0078  0.0157  0.0275  0.0157  0.0196  0.0157  0.0157\n",
       "  0.0118  0.0157  0.0118  0.0118  0.0196  0.0235  0.0196  0.0196  0.0353\n",
       "  0.0078  0.0157  0.0157  0.0118  0.0078  0.0235  0.0196  0.0157  0.0196\n",
       "  0.0078  0.0196  0.0196  0.0157  0.0118  0.0196  0.0314  0.0196  0.0157\n",
       "  0.0118  0.0196  0.0118  0.0078  0.0157  0.0196  0.0118  0.0118  0.0118\n",
       "  0.0118  0.0157  0.0157  0.0078  0.0118  0.0353  0.0157  0.0118  0.0118\n",
       "  0.0078  0.0157  0.0196  0.0157  0.0118  0.0157  0.0157  0.0118  0.0235\n",
       "  0.0078  0.0157  0.0118  0.0118  0.0196  0.0118  0.0118  0.0118  0.0275\n",
       "  0.0039  0.0118  0.0157  0.0078  0.0157  0.0235  0.0196  0.0157  0.0196\n",
       "  0.0039  0.0078  0.0118  0.0118  0.0078  0.0235  0.0078  0.0157  0.0902\n",
       "  0.0078  0.0157  0.0118  0.0118  0.0118  0.0196  0.0118  0.0314  0.2510\n",
       "  0.0078  0.0157  0.0157  0.0078  0.0118  0.0078  0.0039  0.0118  0.0863\n",
       "  0.0118  0.0157  0.0196  0.0078  0.0157  0.0588  0.0588  0.0157  0.0078\n",
       "  0.0118  0.0157  0.0118  0.0118  0.0667  0.3294  0.3922  0.1373  0.0196\n",
       "  0.0118  0.0235  0.0157  0.0118  0.0902  0.4980  0.7608  0.4510  0.1098\n",
       "  0.0039  0.0235  0.0235  0.0118  0.0549  0.3412  0.7843  0.7686  0.3961\n",
       "  0.0039  0.0118  0.0196  0.0118  0.0196  0.1333  0.4980  0.7765  0.7804\n",
       "  0.0078  0.0196  0.0275  0.0157  0.0118  0.0314  0.1294  0.3686  0.6627\n",
       "  0.0118  0.0235  0.0078  0.0118  0.0118  0.0196  0.0196  0.0745  0.1961\n",
       "  0.0118  0.0235  0.0157  0.0118  0.0118  0.0392  0.0235  0.0196  0.0235\n",
       "  0.0078  0.0157  0.0196  0.0078  0.0078  0.0078  0.0118  0.0157  0.0196\n",
       "  0.0078  0.0157  0.0078  0.0078  0.0078  0.0039  0.0039  0.0039  0.0078\n",
       "  0.0039  0.0118  0.0157  0.0118  0.0118  0.0078  0.0118  0.0039  0.0078\n",
       "  0.0000  0.0039  0.0078  0.0196  0.0196  0.0078  0.0078  0.0039  0.0039\n",
       "  0.0039  0.0078  0.0078  0.0196  0.0196  0.0078  0.0039  0.0000  0.0000\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.0039  0.0039  0.0118  0.0078  0.0118  0.0118  0.0157  0.0078  0.0078\n",
       "  0.0078  0.0078  0.0118  0.0118  0.0118  0.0118  0.0157  0.0196  0.0196\n",
       "  0.0196  0.0667  0.1608  0.1804  0.1216  0.0392  0.0157  0.0196  0.0196\n",
       "  0.1020  0.3804  0.7059  0.7608  0.5765  0.2667  0.0941  0.0314  0.0157\n",
       "  0.2118  0.5725  0.7176  0.7451  0.7176  0.6431  0.4392  0.2000  0.0863\n",
       "  0.0706  0.1569  0.1608  0.1725  0.2235  0.4392  0.6863  0.6667  0.4549\n",
       "  0.0118  0.0157  0.0157  0.0196  0.0235  0.0863  0.2941  0.5451  0.5647\n",
       "  0.0118  0.0078  0.0078  0.0157  0.0078  0.0118  0.0510  0.1216  0.1412\n",
       "  0.0118  0.0078  0.0078  0.0196  0.0118  0.0078  0.0078  0.0078  0.0039\n",
       "  0.0118  0.0157  0.0078  0.0196  0.0157  0.0118  0.0157  0.0196  0.0157\n",
       "  0.0157  0.0157  0.0196  0.0235  0.0588  0.1059  0.1843  0.2118  0.1882\n",
       "  0.0627  0.0941  0.1490  0.1882  0.3451  0.5333  0.7176  0.7294  0.6824\n",
       "  0.3059  0.4941  0.6902  0.7255  0.7255  0.7216  0.6235  0.4353  0.3569\n",
       "  0.6706  0.7608  0.7686  0.6510  0.3137  0.2000  0.1333  0.0745  0.0549\n",
       "  0.2471  0.2863  0.2196  0.1608  0.0471  0.0275  0.0196  0.0196  0.0118\n",
       "  0.0196  0.0275  0.0157  0.0196  0.0078  0.0118  0.0118  0.0196  0.0157\n",
       "  0.0078  0.0157  0.0078  0.0196  0.0157  0.0078  0.0157  0.0157  0.0431\n",
       "  0.0196  0.0118  0.0157  0.0078  0.0118  0.0039  0.0196  0.0392  0.1529\n",
       "  0.1176  0.0353  0.0314  0.0118  0.0196  0.0275  0.0745  0.2471  0.4431\n",
       "  0.4667  0.2431  0.2039  0.1608  0.1961  0.2392  0.4039  0.6902  0.7059\n",
       "  0.7569  0.7176  0.7255  0.6667  0.6667  0.6314  0.6039  0.5020  0.2824\n",
       "  0.3686  0.5725  0.6000  0.5176  0.3765  0.3294  0.2118  0.1059  0.0431\n",
       "  0.0510  0.1098  0.1059  0.0941  0.0510  0.0431  0.0196  0.0078  0.0157\n",
       "  0.0078  0.0235  0.0078  0.0157  0.0078  0.0078  0.0196  0.0078  0.0196\n",
       "  0.0078  0.0078  0.0078  0.0078  0.0039  0.0039  0.0196  0.0118  0.0039\n",
       "  0.0157  0.0078  0.0157  0.0078  0.0118  0.0078  0.0196  0.0157  0.0039\n",
       "  0.0118  0.0078  0.0078  0.0078  0.0118  0.0078  0.0118  0.0157  0.0039\n",
       "  0.0000  0.0000  0.0000  0.0039  0.0039  0.0000  0.0000  0.0039  0.0000\n",
       "\n",
       "Columns 18 to 26 \n",
       "   0.0118  0.0078  0.0039  0.0078  0.0118  0.0078  0.0078  0.0118  0.0039\n",
       "  0.0118  0.0078  0.0078  0.0118  0.0118  0.0118  0.0196  0.0235  0.0118\n",
       "  0.0118  0.0118  0.0078  0.0078  0.0118  0.0118  0.0157  0.0196  0.0118\n",
       "  0.0157  0.0118  0.0118  0.0118  0.0118  0.0078  0.0078  0.0078  0.0078\n",
       "  0.0392  0.0118  0.0078  0.0078  0.0078  0.0078  0.0039  0.0078  0.0118\n",
       "  0.2118  0.0431  0.0039  0.0039  0.0078  0.0078  0.0118  0.0118  0.0118\n",
       "  0.3843  0.0863  0.0078  0.0000  0.0078  0.0078  0.0118  0.0078  0.0118\n",
       "  0.1059  0.0314  0.0039  0.0000  0.0039  0.0078  0.0078  0.0118  0.0157\n",
       "  0.0039  0.0039  0.0039  0.0000  0.0039  0.0118  0.0118  0.0118  0.0118\n",
       "  0.0118  0.0118  0.0078  0.0000  0.0078  0.0078  0.0157  0.0078  0.0078\n",
       "  0.1725  0.1804  0.1294  0.0431  0.0078  0.0078  0.0078  0.0118  0.0039\n",
       "  0.5843  0.6275  0.5647  0.2667  0.0549  0.0118  0.0078  0.0157  0.0118\n",
       "  0.3020  0.4157  0.6902  0.6902  0.2941  0.0471  0.0118  0.0118  0.0118\n",
       "  0.0431  0.1020  0.4078  0.7961  0.6510  0.1686  0.0196  0.0078  0.0078\n",
       "  0.0118  0.0314  0.2588  0.7804  0.8196  0.2902  0.0392  0.0157  0.0196\n",
       "  0.0196  0.0784  0.4039  0.8392  0.8196  0.2863  0.0431  0.0118  0.0196\n",
       "  0.1333  0.3294  0.7176  0.8549  0.6784  0.2000  0.0235  0.0039  0.0039\n",
       "  0.4941  0.7725  0.7843  0.5451  0.2235  0.0471  0.0078  0.0078  0.0039\n",
       "  0.7373  0.8314  0.4863  0.1608  0.0314  0.0118  0.0078  0.0118  0.0118\n",
       "  0.6157  0.4941  0.1490  0.0235  0.0118  0.0078  0.0157  0.0118  0.0118\n",
       "  0.1412  0.0902  0.0235  0.0039  0.0078  0.0078  0.0118  0.0078  0.0118\n",
       "  0.0157  0.0118  0.0078  0.0078  0.0118  0.0118  0.0157  0.0157  0.0157\n",
       "  0.0078  0.0118  0.0118  0.0039  0.0039  0.0118  0.0078  0.0157  0.0118\n",
       "  0.0118  0.0118  0.0157  0.0078  0.0078  0.0078  0.0118  0.0157  0.0078\n",
       "  0.0039  0.0078  0.0078  0.0078  0.0039  0.0078  0.0078  0.0157  0.0196\n",
       "  0.0118  0.0118  0.0078  0.0118  0.0118  0.0118  0.0118  0.0157  0.0157\n",
       "  0.0078  0.0196  0.0157  0.0196  0.0157  0.0118  0.0157  0.0157  0.0157\n",
       "  0.0000  0.0118  0.0078  0.0196  0.0078  0.0078  0.0157  0.0196  0.0078\n",
       "\n",
       "Columns 27 to 27 \n",
       "   0.0000\n",
       "  0.0039\n",
       "  0.0118\n",
       "  0.0039\n",
       "  0.0039\n",
       "  0.0078\n",
       "  0.0118\n",
       "  0.0118\n",
       "  0.0078\n",
       "  0.0078\n",
       "  0.0000\n",
       "  0.0039\n",
       "  0.0039\n",
       "  0.0039\n",
       "  0.0078\n",
       "  0.0078\n",
       "  0.0039\n",
       "  0.0039\n",
       "  0.0078\n",
       "  0.0118\n",
       "  0.0196\n",
       "  0.0157\n",
       "  0.0039\n",
       "  0.0078\n",
       "  0.0118\n",
       "  0.0118\n",
       "  0.0157\n",
       "  0.0078\n",
       "[torch.FloatTensor of size 1x28x28]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "RescaleTrans = transforms.Compose([\n",
    "transforms.Scale(28),\n",
    "transforms.ToTensor(),\n",
    "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "torch.FloatTensor(RescaleTrans(Image.fromarray(G_result[0,0].cpu().mul(0.5).add(0.5).mul(255).byte().numpy())).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x7F1C12D2D2E8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(G_result[0,0].cpu().mul(0.5).add(0.5).mul(255).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_result[0].cpu().mul(0.5).add(0.5).mul(255).byte().numpy().dtype\n",
    "# nn.AvgPool2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.0118  0.0078  0.1294  0.1922  0.0196  0.0078  0.0118\n",
       "  0.0118  0.0118  0.1216  0.2863  0.1922  0.0000  0.0118\n",
       "  0.0118  0.0118  0.0549  0.1686  0.2275  0.0784  0.0039\n",
       "  0.0118  0.0275  0.2667  0.2667  0.1922  0.4902  0.0235\n",
       "  0.0078  0.3412  0.2157  0.1020  0.3882  0.3216  0.0078\n",
       "  0.0118  0.0745  0.2980  0.2510  0.1176  0.0000  0.0118\n",
       "  0.0118  0.0000  0.0000  0.0000  0.0000  0.0118  0.0157\n",
       "[torch.FloatTensor of size (1,7,7)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
