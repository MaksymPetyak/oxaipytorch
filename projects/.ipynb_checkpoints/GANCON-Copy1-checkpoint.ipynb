{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 784 # Our images have size 28x28, which is a total of 784 pixels (size of flattened vector)\n",
    "        n_out = 1 # The output of the discriminator is a single number, saying how likely this is a real image (as opposed to generated)\n",
    "        \n",
    "        # We now declare the layers of the network. This create the variables that hold the weights (aka parameters)\n",
    "        # We use the Sequential class, which itself takes a series of modules which define functions, \n",
    "        # and composes these functions, sequentially, feeding the output of one the the input of the next.\n",
    "        # \n",
    "        # Linear is just a matrix multiplication plus bias vector addition\n",
    "        # LeakyReLU is a variant of ReLU, which has non-zero gradient when pre-activation is negative\n",
    "        # Dropout makes some neurons' activation zero (\"drops them\"), with a certain probability. Used as regularizer\n",
    "        # \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100 # The noise vector is of size 100 (pretty arbitrary choice!)\n",
    "        n_out = 784 # The size of the output \"image\"\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# Noise\n",
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): return n.cuda()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "import pickle\n",
    "generator_stat_dict = pickle.load(open(\"trained_generator.pkl\",\"rb\"))\n",
    "discriminator_stat_dict = pickle.load(open(\"trained_discriminator.pkl\",\"rb\"))\n",
    "generator.load_state_dict(generator_stat_dict)\n",
    "discriminator.load_state_dict(discriminator_stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbd4b0e02b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd79b758d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vectors_to_images(generator(noise(1))).data.cpu()[0,0].numpy().shape\n",
    "\n",
    "plt.imshow(vectors_to_images(generator(noise(1))).data.cpu()[0,0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 10, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(10 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "import pickle\n",
    "net.load_state_dict(pickle.load(open(\"trained_mnist_classifier.pkl\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=250, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(net.parameters())\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size (1,) (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = vectors_to_images(generator(noise(1)))\n",
    "\n",
    "_,pred = torch.max(net(input),1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(input):\n",
    "    plt.imshow(input.data.cpu()[0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 7 \n",
       " 14.9694  -5.2208   5.3083  -5.9013  -1.5002  -5.9714   0.6375  -3.4742\n",
       "\n",
       "Columns 8 to 9 \n",
       "  0.2685  -1.5074\n",
       "[torch.cuda.FloatTensor of size (1,10) (GPU 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANCON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "predicted:  4\n",
      "200\n",
      "predicted:  4\n",
      "400\n",
      "predicted:  4\n",
      "600\n",
      "predicted:  4\n",
      "800\n",
      "predicted:  4\n",
      "1000\n",
      "predicted:  4\n",
      "1200\n",
      "predicted:  4\n",
      "1400\n",
      "predicted:  4\n",
      "1600\n",
      "predicted:  4\n",
      "1800\n",
      "predicted:  4\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 100).cuda(), requires_grad=True)\n",
    "optimizer = optim.SGD([input],lr=0.001)\n",
    "cost = F.cross_entropy\n",
    "\n",
    "target_number = 4\n",
    "num_iters = 2000\n",
    "\n",
    "for ii in range(100):\n",
    "    input = Variable(torch.randn(1, 100).cuda(), requires_grad=True)\n",
    "    out = net(vectors_to_images(generator(input)))\n",
    "    _,pred = torch.max(out,1)\n",
    "    pred.data.cpu()[0]\n",
    "    if pred.data.cpu()[0] == target_number:\n",
    "        break\n",
    "\n",
    "target_number = 2\n",
    "for iteration in range(num_iters):\n",
    "    input.grad = input_grad_zeros\n",
    "    prediction = net(vectors_to_images(generator(input)))\n",
    "    loss = cost(prediction,Variable(torch.LongTensor([target_number]).cuda()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%(num_iters//10)==0:\n",
    "        print(iteration)\n",
    "        _,pred = torch.max(prediction,1)\n",
    "        print(\"predicted: \", pred.data.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grad_zeros = Variable(torch.zeros(input.grad.shape).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    prediction = net(vectors_to_images(generator(input)))\n",
    "    loss = cost(prediction,Variable(torch.LongTensor([target_number]).cuda()))\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEFJJREFUeJzt3W2MHfV1x/Hf2fXaa4wLNgbjGFOenDau0zpo46QKqoioKdCoBkWi8QvqqCjmBaiJFKkgKjW0qVpSlUSojaI6YMUQSkKUIKwUtRCrkhWJEhbi2BADJsTENsYGAcUPsLvePX2xQ7SBvWeu79PM+nw/krW7c+7c+fvu/e3ce8/M/M3dBSCfvqoHAKAahB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKzermx2TbHBzWvl5sEUnlHRzXqI9bMbdsKv5ldIelOSf2S7nL326PbD2qePmaXtbNJdFpff1yfGO/NOKZjJc9hDk1/n8d9a9O3bfllv5n1S/q6pCslrZC0zsxWtHp/AHqrnff8qyW94O4vuvuopO9IWtuZYQHotnbCv1TS3ik/7yuW/QYz22Bmw2Y2PKaRNjYHoJO6/mm/u2909yF3HxrQnG5vDkCT2gn/fknLpvx8TrEMwAzQTvifkLTczM43s9mSPiNpS2eGBaDbWm71uftxM7tJ0n9rstW3yd2fKV0xat+007qpc8uqzur8uNDKm16Yoebvpq0+v7s/LOnhdu4DQDU4vBdIivADSRF+ICnCDyRF+IGkCD+QVE/P55cU927bOYWzzv3qk5jNiQ/Z9rHjjYuZf2fdOt7lBLDnB5Ii/EBShB9IivADSRF+ICnCDyTV+1ZfhFM4e67vlFPCetiqk+Sjo/EGot9pyWnYNhA/PftK2ox22m81rB3fuy9ct+vaeFw61SJlzw8kRfiBpAg/kBThB5Ii/EBShB9IivADSdWrz18m6n8ym2xLJo4dq3DjZb+z+Ok5MRJP/+ZV9/Jb1aPnMnt+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iqrT6/me2RdFjSuKTj7j7U1mjK+uUV9vJtVuOHyo/H57xjev1nnhnWD15zUVg/c/NTnRxOOp04yOeT7v5aB+4HQA/xsh9Iqt3wu6RHzOxJM9vQiQEB6I12X/Zf4u77zewsSY+a2bPuvm3qDYo/ChskaVDx9eIA9E5be3533198PSTpQUmrp7nNRncfcvehAcUXXATQOy2H38zmmdn8d7+XdLmkpzs1MADd1c7L/sWSHrTJ9twsSf/h7v/VkVEB6LqWw+/uL0r6gw6Opdbnvft4faeTjq69Hx2fIEnjhw/Hd97m7ySawvvYffPCde+48N/D+lfu+8Ow7iXn+2dHqw9IivADSRF+ICnCDyRF+IGkCD+Q1My6dHcbylpePlHS0qrwdOK+wcGwfnTNyoa1dxbE0z2f8b0dYX3i6NGwXnYa9mt/cXHD2mO/92/huiM+FtY5lbo97PmBpAg/kBThB5Ii/EBShB9IivADSRF+IKk0ff7SnnDZZcPbWdfiv7H9C08P68dWXxDWz735+Ya1n/5wRbjuooGSp0DJ/63v1FPD+pE1RxrWBiw+BmHM42MrfHQ0rCPGnh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkkrT5y/txbdxieq+uXPjTS89O6wf/nA8VfWBT8f97Jd2Lm9YW7F5T7ju8Tf/L6yXmSi79Peu+Y1rl8SrPj9W8jup8aXeZwL2/EBShB9IivADSRF+ICnCDyRF+IGkCD+QVGmf38w2SfqUpEPuvrJYtlDSdyWdJ2mPpGvd/Y3uDbMDutgTtnnxVNP7r4r7/At2x9enP/vB2WH9tMf2Nqwdf/lAuG63/f26+1pe95pHbgrrH9QTLd83mtvzf0vSFe9Zdoukre6+XNLW4mcAM0hp+N19m6TX37N4raTNxfebJV3d4XEB6LJW3/Mvdvd3X0++Imlxh8YDoEfa/sDP3V1SwzfUZrbBzIbNbHhMI+1uDkCHtBr+g2a2RJKKr4ca3dDdN7r7kLsPDWhOi5sD0Gmthn+LpPXF9+slPdSZ4QDoldLwm9n9kh6T9Dtmts/Mrpd0u6Q1ZrZb0h8XPwOYQUr7/O6+rkHpsg6PZcbad13j8+klaeWnd4X13Xf9blhf9MCOsD4ezUnQ7XPeS66TcM289zaKpoqv23/BAxMtDAjN4gg/ICnCDyRF+IGkCD+QFOEHkiL8QFJ5Lt3dRfP3xlNJ/9WSH4X1G2fHrb6Jo0dPeEy9MmvpB8J62TTckf5jJdOqn6y6eJn5qdjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS9Pk74OWr4n70RQPvhPXBN2buVNMHrzy35XWPTcRTj8/atSesx0dXzGA9mnqcPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEWfvwMe+uTXw/ppfYNhvX+kuktU20A8/XffqfH043/++Uda3nZ/2Xnrxr6pm3h0gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCp0j6/mW2S9ClJh9x9ZbHsNkmfk/RqcbNb3f3hbg2yDvrPWNiwNmjxmeVjHv+NPXZWfG37uWE1ZnPmhPX+JYvjOxiJz7kftPhaBuPe+BiGtc9dHa7rb74c1tGeZvb835J0xTTLv+buq4p/J3XwgZNRafjdfZuk13swFgA91M57/pvMbIeZbTKzBR0bEYCeaDX835B0oaRVkg5IuqPRDc1sg5kNm9nwmEZa3ByATmsp/O5+0N3H3X1C0jclrQ5uu9Hdh9x9aEDxh08Aeqel8JvZkik/XiPp6c4MB0CvNNPqu1/SpZIWmdk+SV+SdKmZrZLkkvZIuqGLYwTQBaXhd/d10yy+uwtjqbfxxr38+9/8aLjqLYt+Ftb/8ea74vq+z4b1We80Hturq+JrCSz94Sth/c2PfSCsf3Tuf4b17aONx3bszqXhunNV0ucvux5ApEfXxq8zjvADkiL8QFKEH0iK8ANJEX4gKcIPJDWjLt1tsxoP14/Hp5a2a+Lo2w1r/3vd74frXvynl4b1d1Y0vm9J+tDN+8L6r948vWFtzbLt4bo/febisH72jb8I6ytnj4X1b791YcPa/B0Hw3XLfqM2ayCuDzR+vkwcO1Zy7yc/9vxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNSM6vN3u5cfbnus8SWsfcez4brn7IxPPe075ZSwvuvLHw7rS7c1vjz2rucvCtedPTc+xuDL524J6y+Px9OL/+u9axvWlu39SbhuGRuMrwzlbwf/t7LTgROc8sueH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSmlF9/hmrpGc8cfRoWF/+18Px3QfHP4z3xdN/961cHtbP7I/7+AOK++VLtzU+b96Dy6FP3qDkcTtyJF6/jfvOgD0/kBThB5Ii/EBShB9IivADSRF+ICnCDyRV2uc3s2WS7pG0WJJL2ujud5rZQknflXSepD2SrnX3N0q3GJ1HTe91Wt28jsHfPXRvWD+jb25Yf/TtuN43vKthzdv9fZet384U3jUWzV9ROtnBFM3s+Y9L+qK7r5D0cUk3mtkKSbdI2uruyyVtLX4GMEOUht/dD7j7U8X3hyXtkrRU0lpJm4ubbZZ0dbcGCaDzTug9v5mdJ+kjkh6XtNjdDxSlVzT5tgDADNF0+M3sVEnfl/QFd39ras0n37xN+wbMzDaY2bCZDY9ppK3BAuicpsJvZgOaDP597v6DYvFBM1tS1JdIOjTduu6+0d2H3H1oQPEFFwH0Tmn4zcwk3S1pl7t/dUppi6T1xffrJT3U+eEB6JZmTun9hKTrJO00s3fne75V0u2SHjCz6yW9JOnaprbYpXZe2P5QtZf9rtLo5fEU3Kf3bQvrExoM63/7D38Z1heMPBbWa6vkVGh5fKpzN9vW4XP5BDZbGn53/7HU8KTty5rfFIA64Qg/ICnCDyRF+IGkCD+QFOEHkiL8QFIz69LdwSmaWfv4ZbykXX3+rLiPv2M0vrz26bvjKb4r1Uav3QZKjhsZmfmHqrPnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkZlafn0t7n7ADH49/xUcm4n71P+37s7A+69lfhfWSSbhrq+t9/Bpcwp49P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1fs+fw36myed4Brzo2fEnfbvHbkorP/y28vD+qI3fhLW0UA7z/UwQ83fDXt+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iqtM9vZssk3SNpsSa7iBvd/U4zu03S5yS9Wtz0Vnd/OL4zyfob96QrvfZ+1DuV6n0MwkTjXv6HvvTLcNWvzP+TsL787ifCugfbntFKng/R81iSfLzkcWnn+dSh52IzB/kcl/RFd3/KzOZLetLMHi1qX3P3f+nISAD0VGn43f2ApAPF94fNbJekpd0eGIDuOqH3/GZ2nqSPSHq8WHSTme0ws01mtqDBOhvMbNjMhsd85k9xBJwsmg6/mZ0q6fuSvuDub0n6hqQLJa3S5CuDO6Zbz903uvuQuw8N2JwODBlAJzQVfjMb0GTw73P3H0iSux9093F3n5D0TUmruzdMAJ1WGn4zM0l3S9rl7l+dsnzJlJtdI+npzg8PQLc082n/JyRdJ2mnmW0vlt0qaZ2ZrdJk+2+PpBvK78okq+mhBXVu5bXjrIVh+YM3PBfWJ8paVierkudDV9vSPWo7N/Np/48lTTeauKcPoNZquhsG0G2EH0iK8ANJEX4gKcIPJEX4gaR6e+lud/nYaHfuO7h8taTwtNeT2fgzcR8fNcQU3QC6ifADSRF+ICnCDyRF+IGkCD+QFOEHkjLv4XnsZvaqpJemLFok6bWeDeDE1HVsdR2XxNha1cmx/ba7n9nMDXsa/vdt3GzY3YcqG0CgrmOr67gkxtaqqsbGy34gKcIPJFV1+DdWvP1IXcdW13FJjK1VlYyt0vf8AKpT9Z4fQEUqCb+ZXWFmz5nZC2Z2SxVjaMTM9pjZTjPbbmbDFY9lk5kdMrOnpyxbaGaPmtnu4uu006RVNLbbzGx/8dhtN7OrKhrbMjP7HzP7uZk9Y2afL5ZX+tgF46rkcev5y34z65f0vKQ1kvZJekLSOnf/eU8H0oCZ7ZE05O6V94TN7I8kHZF0j7uvLJb9s6TX3f324g/nAne/uSZju03Skapnbi4mlFkydWZpSVdL+qwqfOyCcV2rCh63Kvb8qyW94O4vuvuopO9IWlvBOGrP3bdJev09i9dK2lx8v1mTT56eazC2WnD3A+7+VPH9YUnvzixd6WMXjKsSVYR/qaS9U37ep3pN+e2SHjGzJ81sQ9WDmcbiYtp0SXpF0uIqBzON0pmbe+k9M0vX5rFrZcbrTuMDv/e7xN0vlnSlpBuLl7e15JPv2erUrmlq5uZemWZm6V+r8rFrdcbrTqsi/PslLZvy8znFslpw9/3F10OSHlT9Zh8++O4kqcXXQxWP59fqNHPzdDNLqwaPXZ1mvK4i/E9IWm5m55vZbEmfkbSlgnG8j5nNKz6IkZnNk3S56jf78BZJ64vv10t6qMKx/Ia6zNzcaGZpVfzY1W7Ga3fv+T9JV2nyE/9fSPqbKsbQYFwXSPpZ8e+Zqscm6X5Nvgwc0+RnI9dLOkPSVkm7Jf1I0sIaje1eSTsl7dBk0JZUNLZLNPmSfoek7cW/q6p+7IJxVfK4cYQfkBQf+AFJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSOr/AfgqITtsTFpdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd7953fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(vectors_to_images(generator(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(vectors_to_images(generator(input)))\n",
    "_,pred = torch.max(out,1)\n",
    "pred.data.cpu()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
