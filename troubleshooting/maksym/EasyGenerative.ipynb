{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook following this blogpost: <br>\n",
    "https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: what does this function do?\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list from a variable object\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "# returns mu,variance for a given array (not variable!)\n",
    "# works with extract, see example below\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tensor:\n",
      "Variable containing:\n",
      " 0.0271 -0.8832\n",
      " 0.7581 -0.2634\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "[0.027085527777671814, -0.883240818977356, 0.7581320405006409, -0.2634291648864746]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.090363103896379471, 0.58998837354775158]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.Tensor(torch.randn(2,2)))\n",
    "print(\"Our tensor:\", x, sep =\"\\n\")\n",
    "print(extract(x))\n",
    "stats(extract(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Raw data]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment only one of these\n",
    "(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns gaussian function with mean mu and var sigma\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "\n",
    "#returns a funciton capable of generation random numbers\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n) # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x) # no activations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create samplers for networks\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "\n",
    "# create networks, see params higher\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "\n",
    "#define optimizier for both networks\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 1.2101160287857056/0.6485859155654907 G: 0.7444975972175598 \n",
      "(Real: [4.0160312485694885, 1.2764931997490707], Fake: [-0.2030932642519474, 0.001100026122854983]) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: D: 0.17556071281433105/0.5551384091377258 G: 0.8623489141464233 \n",
      "(Real: [3.9404023426771162, 1.2416657755338121], Fake: [1.3736900115013122, 0.070557733591906452]) \n",
      "400: D: 0.8309756517410278/0.8656553626060486 G: 0.5659179091453552 \n",
      "(Real: [4.0358939003944396, 1.2840827517909839], Fake: [3.665249991416931, 0.11772644355718874]) \n",
      "600: D: 0.8060558438301086/0.8244041800498962 G: 0.5962673425674438 \n",
      "(Real: [4.1958333897590636, 1.3143381074060152], Fake: [5.277332954406738, 0.10932349391769729]) \n",
      "800: D: 0.9875590205192566/0.4799656271934509 G: 1.0010446310043335 \n",
      "(Real: [3.873040654063225, 1.2243600347548818], Fake: [5.9661702203750613, 0.10097086839537393]) \n",
      "1000: D: 0.7064688801765442/0.40801751613616943 G: 1.1727526187896729 \n",
      "(Real: [4.0906891226768494, 1.1153377969224756], Fake: [5.6164121770858761, 0.10323083813304613]) \n",
      "1200: D: 0.40916234254837036/0.6069835424423218 G: 0.8213219046592712 \n",
      "(Real: [4.0312618210911753, 1.3107701121734781], Fake: [4.241436047554016, 0.1145498296108963]) \n",
      "1400: D: 0.6578137278556824/0.7963911890983582 G: 0.5723205208778381 \n",
      "(Real: [4.0999833476543426, 1.2359121461783431], Fake: [3.0725743269920347, 0.12696729622867639]) \n",
      "1600: D: 0.5885560512542725/0.6874386668205261 G: 0.7012062668800354 \n",
      "(Real: [4.0002272361516953, 1.1953753176209396], Fake: [4.0150876832008358, 0.14194653746658667]) \n",
      "1800: D: 0.7226895689964294/0.49524298310279846 G: 0.9042954444885254 \n",
      "(Real: [4.1822193777561187, 1.0985558891357368], Fake: [4.6660780525207519, 0.12300585848148006]) \n",
      "2000: D: 0.6064996123313904/0.7474117875099182 G: 0.6503963470458984 \n",
      "(Real: [4.0026217865943909, 1.1121725426607723], Fake: [3.5794272613525391, 0.14071696239951606]) \n",
      "2200: D: 0.8256967067718506/0.6693349480628967 G: 0.700370192527771 \n",
      "(Real: [3.7044223946332933, 1.2342211407507173], Fake: [3.8060908532142639, 0.15970643720904149]) \n",
      "2400: D: 0.40287134051322937/0.7565100789070129 G: 0.679381787776947 \n",
      "(Real: [4.0034800338745118, 1.2518963795413651], Fake: [4.1469488549232487, 0.1626514829584341]) \n",
      "2600: D: 0.5443271994590759/0.6823141574859619 G: 0.6736137866973877 \n",
      "(Real: [4.1692783588171007, 1.2958807499924243], Fake: [3.5370897293090819, 0.19158702499004945]) \n",
      "2800: D: 0.24932344257831573/0.6086556911468506 G: 0.7075284123420715 \n",
      "(Real: [3.9324147552251816, 1.2998328495646185], Fake: [3.8886996459960939, 0.24683213294378739]) \n",
      "3000: D: 0.2522638142108917/0.4481443762779236 G: 0.8451750874519348 \n",
      "(Real: [3.894199467897415, 1.1859646965305755], Fake: [4.2818876123428344, 0.27309469245881607]) \n",
      "3200: D: 0.8773211240768433/0.5158396363258362 G: 0.6446820497512817 \n",
      "(Real: [4.2884766042232512, 1.2565301425308901], Fake: [3.7425837039947512, 0.62179542560248746]) \n",
      "3400: D: 1.6870861053466797/0.4831183850765228 G: 0.5670740604400635 \n",
      "(Real: [3.8808239221572878, 1.2666329301560635], Fake: [3.619727053642273, 1.2878342650440493]) \n",
      "3600: D: 0.6042361855506897/0.5713102221488953 G: 0.9622306823730469 \n",
      "(Real: [3.796376667022705, 1.3112863140260775], Fake: [5.8969035339355464, 1.3299645601903753]) \n",
      "3800: D: 0.32843589782714844/0.32006844878196716 G: 1.4336210489273071 \n",
      "(Real: [3.9969274841248987, 1.244479720571193], Fake: [2.8016674261540175, 2.1812803666687377]) \n",
      "4000: D: 0.6534604430198669/0.8139058947563171 G: 1.1107844114303589 \n",
      "(Real: [4.0562939268350604, 1.2299626381684043], Fake: [5.6464628338813778, 2.0124172250487145]) \n",
      "4200: D: 0.5669020414352417/0.39626941084861755 G: 0.6700897216796875 \n",
      "(Real: [3.9475732856988905, 1.2849196593284886], Fake: [3.7340968164056538, 1.9629902990065839]) \n",
      "4400: D: 0.5659890174865723/0.7607955932617188 G: 0.7910189628601074 \n",
      "(Real: [3.9774852356314661, 1.282958694931015], Fake: [4.6154275894165036, 1.493666705505311]) \n",
      "4600: D: 0.531838595867157/0.7390963435173035 G: 0.7613236904144287 \n",
      "(Real: [3.9881793290376661, 1.3988107857334089], Fake: [3.9698455786705016, 1.1141104861682147]) \n",
      "4800: D: 0.6370479464530945/0.7757246494293213 G: 0.8240065574645996 \n",
      "(Real: [4.0009336686134338, 1.1806529340695671], Fake: [3.7356960773468018, 1.1720056804548546]) \n",
      "5000: D: 0.7940311431884766/0.744006335735321 G: 0.6955806612968445 \n",
      "(Real: [4.0213304790854458, 1.2475123407681068], Fake: [3.877841489315033, 0.93860635447733787]) \n",
      "5200: D: 0.7571601271629333/0.7157890796661377 G: 0.7426198720932007 \n",
      "(Real: [4.0637387418746949, 1.173611516581037], Fake: [3.8610418140888214, 1.0123384389832515]) \n",
      "5400: D: 0.5345880389213562/0.6941632628440857 G: 0.6464100480079651 \n",
      "(Real: [3.9547470092773436, 1.3569361067584522], Fake: [4.0424379348754886, 0.86662165423351478]) \n",
      "5600: D: 0.6765229105949402/0.6982160210609436 G: 0.6290303468704224 \n",
      "(Real: [3.9573716408014299, 1.2245759839316304], Fake: [3.7320814359188081, 0.89749445986503229]) \n",
      "5800: D: 0.8464511036872864/0.7024310231208801 G: 0.6812165379524231 \n",
      "(Real: [4.2219012153148654, 1.2818975588922072], Fake: [4.1427308225631716, 0.82724108402757501]) \n",
      "6000: D: 0.5151381492614746/0.5991402864456177 G: 0.6131277680397034 \n",
      "(Real: [3.9825235533714296, 1.1756619687167522], Fake: [3.9225049734115602, 0.76775303972524822]) \n",
      "6200: D: 0.7657350897789001/0.6704774498939514 G: 0.6656621098518372 \n",
      "(Real: [4.068735811114311, 1.3451744319183268], Fake: [4.1516275548934933, 0.79729103277209534]) \n",
      "6400: D: 0.7110670804977417/0.66291344165802 G: 0.6451852917671204 \n",
      "(Real: [3.9342073649168015, 1.3891224213233389], Fake: [3.9405197000503538, 0.93101830357336324]) \n",
      "6600: D: 0.645986020565033/0.6911202073097229 G: 0.593914270401001 \n",
      "(Real: [4.1752739107608798, 1.2234120971870446], Fake: [3.8792667639255525, 0.85024962080117961]) \n",
      "6800: D: 0.6197712421417236/0.6326014995574951 G: 0.8124697804450989 \n",
      "(Real: [3.9295284852385519, 1.3635895088730872], Fake: [4.0681111478805541, 1.0299264053153372]) \n",
      "7000: D: 0.7516323924064636/0.7691596150398254 G: 0.6915828585624695 \n",
      "(Real: [4.103662784099579, 1.3176025659316741], Fake: [4.2781107985973357, 1.1564617945618081]) \n",
      "7200: D: 0.5772091150283813/0.6258688569068909 G: 0.5898314714431763 \n",
      "(Real: [4.1594005310535431, 1.2813492717245856], Fake: [3.748532658815384, 1.3267894123297621]) \n",
      "7400: D: 0.6593562960624695/0.8564162850379944 G: 0.6732407808303833 \n",
      "(Real: [4.0860835313796997, 1.2142938574061093], Fake: [3.4641993305087091, 1.5151079389861084]) \n",
      "7600: D: 0.6632826924324036/0.6008150577545166 G: 0.7724005579948425 \n",
      "(Real: [3.9208538538496942, 1.3249442312354911], Fake: [4.8143384611606601, 1.3670266209525861]) \n",
      "7800: D: 0.9925851225852966/0.5710387825965881 G: 0.8299062252044678 \n",
      "(Real: [3.9919290083646772, 1.2495578790146116], Fake: [5.0283988285064698, 1.1730250299896046]) \n",
      "8000: D: 0.6339381337165833/0.7834372520446777 G: 0.549747884273529 \n",
      "(Real: [3.9127392959594727, 1.3261500659769243], Fake: [3.3145168995857239, 1.1408413175812384]) \n",
      "8200: D: 0.6535225510597229/0.5895242094993591 G: 0.9057261943817139 \n",
      "(Real: [3.6917727106809615, 1.1858800325661496], Fake: [4.9857841205596927, 0.97537832897948873]) \n",
      "8400: D: 0.6650853157043457/0.7122830152511597 G: 0.6082723140716553 \n",
      "(Real: [4.1367378520965579, 1.223726935771196], Fake: [3.5851921200752259, 1.0421238580322756]) \n",
      "8600: D: 0.6095134019851685/0.6996510028839111 G: 0.7489688396453857 \n",
      "(Real: [3.9571110939979555, 1.3177550496133998], Fake: [4.2630782115459445, 1.0592834297261533]) \n",
      "8800: D: 0.5893537402153015/0.6189498901367188 G: 0.7121437191963196 \n",
      "(Real: [4.0138203334808349, 1.3000275259891154], Fake: [4.1959310173988342, 1.060221679629801]) \n",
      "9000: D: 0.5422732830047607/0.7547495365142822 G: 0.588011622428894 \n",
      "(Real: [4.1564741545915602, 1.5690761491974612], Fake: [3.4506198656558991, 1.0484135202733589]) \n",
      "9200: D: 0.7841587662696838/0.6543289422988892 G: 0.880829930305481 \n",
      "(Real: [3.9502211701869965, 1.1935394725381234], Fake: [4.6116858386993407, 1.1883210435950367]) \n",
      "9400: D: 0.7893579006195068/0.6098188757896423 G: 0.8187480568885803 \n",
      "(Real: [3.779060637354851, 1.3463248075039969], Fake: [4.11031217455864, 1.1936822238385125]) \n",
      "9600: D: 0.46817177534103394/0.8580920696258545 G: 0.6123414039611816 \n",
      "(Real: [3.9838954955339432, 1.2333868167365776], Fake: [3.4549086916446687, 1.2575709527357606]) \n",
      "9800: D: 0.7782893180847168/0.6077837347984314 G: 0.6995075941085815 \n",
      "(Real: [4.2233876943588253, 1.1630138813006135], Fake: [5.1281712675094608, 1.0680849469676073]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.7772295475006104/0.7340304851531982 G: 0.5596606135368347 \n",
      "(Real: [4.0489641654491422, 1.2296461622883443], Fake: [3.046853095293045, 1.2732438684621783]) \n",
      "10200: D: 0.8809556365013123/0.4738127887248993 G: 0.8162707090377808 \n",
      "(Real: [4.0264144527912142, 1.0627024098836459], Fake: [4.772911756038666, 1.128546453457679]) \n",
      "10400: D: 0.6570205092430115/0.7955340147018433 G: 0.5795419216156006 \n",
      "(Real: [3.9849056173861026, 1.355779374991402], Fake: [3.2306370759010314, 1.2181721279144688]) \n",
      "10600: D: 0.7312461733818054/0.6392481327056885 G: 0.7741319537162781 \n",
      "(Real: [4.0229061871767042, 1.285692880132558], Fake: [4.808013472557068, 1.0787925434220746]) \n",
      "10800: D: 0.7360827922821045/0.71989905834198 G: 0.6758870482444763 \n",
      "(Real: [4.2712983047962192, 1.2936568086199165], Fake: [3.655003753900528, 1.2057611452181296]) \n",
      "11000: D: 0.7715901136398315/0.6487645506858826 G: 0.9155619144439697 \n",
      "(Real: [3.8807445156574247, 1.2592725705443231], Fake: [4.4458279657363891, 1.117475393645885]) \n",
      "11200: D: 0.6598452925682068/0.7870815992355347 G: 0.6683954000473022 \n",
      "(Real: [4.0153416299819948, 1.1489043318234911], Fake: [3.6960095465183258, 1.1872195258444689]) \n",
      "11400: D: 0.5871579051017761/0.6933408975601196 G: 0.7970723509788513 \n",
      "(Real: [3.7493853044509886, 1.2105327201038569], Fake: [3.9361095857620239, 1.2156458534198733]) \n",
      "11600: D: 0.7770114541053772/0.5955250859260559 G: 0.7169298529624939 \n",
      "(Real: [3.8935653012990952, 1.3361838797825381], Fake: [4.2602911710739138, 1.1972838436249984]) \n",
      "11800: D: 0.5356525778770447/0.7830813527107239 G: 0.555284857749939 \n",
      "(Real: [3.9911956048011779, 1.3238376066860045], Fake: [3.6793613111972809, 1.2614961377619922]) \n",
      "12000: D: 0.7911974787712097/0.6913315057754517 G: 0.7408452033996582 \n",
      "(Real: [4.1569143939018254, 1.0820668481102944], Fake: [4.4449177098274228, 1.2134190104642566]) \n",
      "12200: D: 0.6253626942634583/0.6833978891372681 G: 0.8112829327583313 \n",
      "(Real: [3.9735872697830201, 1.1934052645825579], Fake: [3.8797230207920075, 1.1810137921694674]) \n",
      "12400: D: 0.6429592967033386/0.6923938393592834 G: 0.6605220437049866 \n",
      "(Real: [4.1972898036241535, 1.3790177509137231], Fake: [3.860088220834732, 0.98735884089610426]) \n",
      "12600: D: 0.688306987285614/0.6254588961601257 G: 0.740019679069519 \n",
      "(Real: [3.9597825664281845, 1.2433813512034444], Fake: [4.3059218788146971, 1.138210001474093]) \n",
      "12800: D: 0.6177808046340942/0.7531310319900513 G: 0.6500649452209473 \n",
      "(Real: [3.9206329131126405, 1.1899201288575105], Fake: [3.6134742176532746, 1.1823371642198879]) \n",
      "13000: D: 0.7393133044242859/0.6532508730888367 G: 0.7311124801635742 \n",
      "(Real: [3.9209396690130234, 1.3086696740107604], Fake: [3.6982518661022188, 1.2618806219196494]) \n",
      "13200: D: 0.7201980352401733/0.6407013535499573 G: 0.8159011006355286 \n",
      "(Real: [3.9422716283798218, 1.2944084620686351], Fake: [4.3056078314781185, 1.274763292096289]) \n",
      "13400: D: 0.7203704714775085/0.5739173293113708 G: 0.7476322650909424 \n",
      "(Real: [4.0374487638473511, 1.1754529248785519], Fake: [3.7356210160255432, 1.3549255296359928]) \n",
      "13600: D: 0.5562431812286377/0.7267031073570251 G: 0.6207192540168762 \n",
      "(Real: [3.8884308499097826, 1.2148588253141219], Fake: [3.5628220546245575, 1.1600620506132775]) \n",
      "13800: D: 0.7806861400604248/0.6386712193489075 G: 0.8047342300415039 \n",
      "(Real: [3.9372681391239168, 1.1206445055504635], Fake: [4.1314489150047304, 1.1590090764916809]) \n",
      "14000: D: 0.695056676864624/0.6965630054473877 G: 0.8511819839477539 \n",
      "(Real: [4.1929207395203409, 1.3314962701744761], Fake: [4.9726941299438474, 1.0682657902626316]) \n",
      "14200: D: 0.6762014031410217/0.7101498246192932 G: 0.6965033411979675 \n",
      "(Real: [3.866190794110298, 1.1903174382925812], Fake: [3.7236116826534271, 1.2007305898082525]) \n",
      "14400: D: 0.688461184501648/0.7258433699607849 G: 0.6703402400016785 \n",
      "(Real: [4.1788616275787351, 1.1459423147182337], Fake: [3.5378143370151518, 1.158798103859519]) \n",
      "14600: D: 0.6279070973396301/0.7797532081604004 G: 0.7936586141586304 \n",
      "(Real: [3.9781036031246186, 1.4320134565930436], Fake: [4.5638925433158875, 1.1363562776997447]) \n",
      "14800: D: 0.6408228278160095/0.8235164284706116 G: 0.6054627299308777 \n",
      "(Real: [3.7790847206115723, 1.4053593477032846], Fake: [3.6575015997886657, 1.067226689119871]) \n",
      "15000: D: 0.7015981078147888/0.6261733770370483 G: 0.5927311778068542 \n",
      "(Real: [3.8800762629508974, 1.2057025294572012], Fake: [3.9919114553928376, 1.0508602051142657]) \n",
      "15200: D: 0.7210550904273987/0.6805177330970764 G: 0.765407145023346 \n",
      "(Real: [3.9820551472902297, 1.4187653520318875], Fake: [4.7438738656044004, 1.0839335158881851]) \n",
      "15400: D: 0.5474975109100342/0.6751968860626221 G: 0.5387763381004333 \n",
      "(Real: [4.3909698033332827, 1.2371521320655663], Fake: [3.3544958221912382, 1.3244562725941831]) \n",
      "15600: D: 0.6851893067359924/0.7128835916519165 G: 0.7674943804740906 \n",
      "(Real: [3.9415811347961425, 1.1140381400864896], Fake: [4.3033908295631411, 1.2120888676254771]) \n",
      "15800: D: 0.7190519571304321/0.5465062260627747 G: 0.7915645837783813 \n",
      "(Real: [3.9759657335281373, 1.2599628992183523], Fake: [4.6080326557159426, 1.202008392903134]) \n",
      "16000: D: 0.5854517221450806/0.7173425555229187 G: 0.6697365045547485 \n",
      "(Real: [4.0923936355113986, 1.2203166501107243], Fake: [3.3424981904029845, 1.1829875264693046]) \n",
      "16200: D: 0.6585941314697266/0.6968826651573181 G: 0.8018395900726318 \n",
      "(Real: [3.8622321343421935, 1.2555324343553904], Fake: [4.5448748111724857, 1.1791048049564554]) \n",
      "16400: D: 0.8634189367294312/0.6568828821182251 G: 0.7173643112182617 \n",
      "(Real: [3.9793602585792542, 1.3044993883140101], Fake: [4.0529658901691441, 1.2286795565568891]) \n",
      "16600: D: 0.655284583568573/0.7460178732872009 G: 0.6371171474456787 \n",
      "(Real: [4.0187288844585423, 1.1794302990565726], Fake: [3.7991098594665527, 1.0448088183679716]) \n",
      "16800: D: 0.8290764689445496/0.5380841493606567 G: 0.7450913786888123 \n",
      "(Real: [3.9179675775766372, 1.2803157703168373], Fake: [4.7952714586257938, 1.0730643066891565]) \n",
      "17000: D: 0.6125178933143616/0.8269162178039551 G: 0.5277248024940491 \n",
      "(Real: [4.0499220174551009, 1.1883956644110849], Fake: [3.4901428538560868, 0.9890635183959251]) \n",
      "17200: D: 0.7905107736587524/0.47074127197265625 G: 0.8114455938339233 \n",
      "(Real: [4.0206444132328034, 1.3479738231477953], Fake: [4.6916391444206234, 1.0238588647699138]) \n",
      "17400: D: 0.5725566744804382/0.6673617362976074 G: 0.6231617331504822 \n",
      "(Real: [3.9396576437354089, 1.2616512541288158], Fake: [3.4952081561088564, 1.1570215636386252]) \n",
      "17600: D: 0.7938263416290283/0.5917676091194153 G: 0.7480552196502686 \n",
      "(Real: [4.1487544262409211, 1.2679879249492547], Fake: [4.4353969645500184, 1.1426843412106411]) \n",
      "17800: D: 0.6049900054931641/0.69293612241745 G: 0.625016987323761 \n",
      "(Real: [3.8503847420215607, 1.1324880813173581], Fake: [3.6524030160903931, 1.313522615559229]) \n",
      "18000: D: 0.6804266571998596/0.6477003693580627 G: 0.8028339147567749 \n",
      "(Real: [4.0219696775078777, 1.2206108939618074], Fake: [4.2174479687213902, 1.2667929254436892]) \n",
      "18200: D: 0.726491391658783/0.5553663372993469 G: 0.8261122107505798 \n",
      "(Real: [4.0205348122119906, 1.2316883570335164], Fake: [4.2703671634197233, 1.2322536870884888]) \n",
      "18400: D: 0.6750686168670654/0.7225900292396545 G: 0.5836642980575562 \n",
      "(Real: [3.905580769777298, 1.3337779289335636], Fake: [3.7208185374736784, 1.2049175559002758]) \n",
      "18600: D: 0.6620208024978638/0.5825491547584534 G: 0.8344268798828125 \n",
      "(Real: [3.9816889929771424, 1.1268692049945888], Fake: [4.5645655143260955, 1.0353131135357594]) \n",
      "18800: D: 0.5350654721260071/0.7129309177398682 G: 0.6658725142478943 \n",
      "(Real: [4.0658107483386994, 1.2004586633019969], Fake: [3.7105520737171171, 1.1408053785527028]) \n",
      "19000: D: 0.6396323442459106/0.7211365103721619 G: 0.7442418932914734 \n",
      "(Real: [4.0127344447374345, 1.2835612111892487], Fake: [4.1518950104713443, 1.1474876464354591]) \n",
      "19200: D: 0.7038325071334839/0.6793402433395386 G: 0.6478061079978943 \n",
      "(Real: [3.7732164382934572, 1.2252670446888363], Fake: [4.1347439718246459, 1.1827264181543451]) \n",
      "19400: D: 0.6169528365135193/0.6869012713432312 G: 0.6884077191352844 \n",
      "(Real: [3.8246074783802033, 1.2262821162330897], Fake: [3.6814300394058228, 1.2624130927598742]) \n",
      "19600: D: 0.7020434141159058/0.7468242049217224 G: 0.7088799476623535 \n",
      "(Real: [3.8211115106940268, 1.3428201393127448], Fake: [3.9389515554904939, 1.3068313221690868]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800: D: 0.835269570350647/0.5151991248130798 G: 0.6350280046463013 \n",
      "(Real: [3.8301703524589539, 1.2480546073649941], Fake: [4.3116613805294035, 1.1643201445779585]) \n",
      "20000: D: 0.6759535074234009/0.7452389597892761 G: 0.6394375562667847 \n",
      "(Real: [3.9457636463642118, 1.3692178061722438], Fake: [3.3674484515190124, 1.3482518133976642]) \n",
      "20200: D: 0.7020516991615295/0.6686930060386658 G: 0.690633237361908 \n",
      "(Real: [4.0230103302001954, 1.2289659482187014], Fake: [3.9353762686252596, 1.2018887976381365]) \n",
      "20400: D: 0.737435519695282/0.6922870874404907 G: 0.8274880051612854 \n",
      "(Real: [3.8425655543804167, 1.0942578549386885], Fake: [4.3888791835308076, 1.1774804242792212]) \n",
      "20600: D: 0.6452497243881226/0.6285393834114075 G: 0.7303392291069031 \n",
      "(Real: [3.9005243074893952, 1.3000646815722825], Fake: [4.2294338858127594, 1.2225968897719497]) \n",
      "20800: D: 0.6966481804847717/0.6665687561035156 G: 0.7061999440193176 \n",
      "(Real: [3.9519964307546616, 1.2246550064894532], Fake: [3.6354426729679106, 1.2233932328355719]) \n",
      "21000: D: 0.6770358681678772/0.7130972743034363 G: 0.6792173981666565 \n",
      "(Real: [3.9985211318731309, 1.2925275664222438], Fake: [3.8115865433216096, 1.3428684891224247]) \n",
      "21200: D: 0.6932666301727295/0.6081036329269409 G: 0.7118149995803833 \n",
      "(Real: [3.9357023584842681, 1.2275147054950055], Fake: [4.5642914533615109, 1.2070351281596534]) \n",
      "21400: D: 0.7328690886497498/0.7121532559394836 G: 0.8092407584190369 \n",
      "(Real: [4.1061683249473573, 1.0847689869785069], Fake: [4.7808315432071682, 1.0518391909081832]) \n",
      "21600: D: 0.6220889091491699/0.7353563904762268 G: 0.6390526294708252 \n",
      "(Real: [4.04959764957428, 1.1989198910333372], Fake: [3.5323310840129851, 1.3035147144905295]) \n",
      "21800: D: 0.6693365573883057/0.7315810918807983 G: 0.6515604853630066 \n",
      "(Real: [4.0448397666215898, 1.2188523696743372], Fake: [3.5846602642536163, 1.119573379319214]) \n",
      "22000: D: 0.7405787110328674/0.6892107725143433 G: 0.7603559494018555 \n",
      "(Real: [3.8537429150193931, 1.3217170828794538], Fake: [4.2958984422683715, 1.0379744992474012]) \n",
      "22200: D: 0.8146410584449768/0.6905989050865173 G: 0.7065088748931885 \n",
      "(Real: [4.0529637193679813, 1.2259845601815993], Fake: [4.5541847252845766, 1.1579977013684681]) \n",
      "22400: D: 0.6435369253158569/0.7138946056365967 G: 0.6803950071334839 \n",
      "(Real: [4.2039819407463073, 1.234298957349655], Fake: [3.5574006688594819, 1.1051407589294031]) \n",
      "22600: D: 0.6091904044151306/0.7585142254829407 G: 0.7093340158462524 \n",
      "(Real: [3.8654226890206336, 1.373365168455208], Fake: [3.5715901660919189, 1.3424728497683025]) \n",
      "22800: D: 0.7813336253166199/0.5640089511871338 G: 0.8103653192520142 \n",
      "(Real: [3.9760676190257072, 1.3574232549542289], Fake: [4.6979880785942081, 1.2237514823165876]) \n",
      "23000: D: 0.7199050188064575/0.7632713913917542 G: 0.7036393284797668 \n",
      "(Real: [3.792474035322666, 1.2163022112921533], Fake: [3.9418839645385741, 1.2694475567967827]) \n",
      "23200: D: 0.7171058654785156/0.7885907888412476 G: 0.6834802627563477 \n",
      "(Real: [4.1304798811674122, 1.2592178416091857], Fake: [3.6199236494302749, 1.2638685690695879]) \n",
      "23400: D: 0.7010799646377563/0.5984832644462585 G: 0.6761175990104675 \n",
      "(Real: [4.0572365438938141, 1.2042586640597919], Fake: [4.4262710833549503, 1.1497737180499021]) \n",
      "23600: D: 0.7283194065093994/0.6886329650878906 G: 0.6961327195167542 \n",
      "(Real: [3.8504166325926779, 1.4062746418208312], Fake: [3.7606877458095549, 1.2994720233696082]) \n",
      "23800: D: 0.5900800824165344/0.7895282506942749 G: 0.6824293732643127 \n",
      "(Real: [3.8538363042846324, 1.3200864309717291], Fake: [3.658346300125122, 1.2328404852146537]) \n",
      "24000: D: 0.7119731903076172/0.6341784000396729 G: 0.7887359261512756 \n",
      "(Real: [3.8064431762695312, 1.1480173700821217], Fake: [4.4902928709983829, 1.0707647501455975]) \n",
      "24200: D: 0.7010961174964905/0.6888974905014038 G: 0.7539575695991516 \n",
      "(Real: [3.954183419942856, 1.3611801766592269], Fake: [4.4138634431362149, 1.1583064336266911]) \n",
      "24400: D: 0.6641148924827576/0.7817381024360657 G: 0.6900933980941772 \n",
      "(Real: [3.9618360372632742, 1.3070497924014779], Fake: [3.2216641175746918, 1.2393172688537579]) \n",
      "24600: D: 0.7062426209449768/0.5851817727088928 G: 0.8333096504211426 \n",
      "(Real: [4.0309407019615175, 1.1678179549084593], Fake: [4.6054285383224487, 1.1013130568909124]) \n",
      "24800: D: 0.7095203995704651/0.673933744430542 G: 0.6860612630844116 \n",
      "(Real: [3.8439180517196654, 1.2169254714944249], Fake: [3.8466217887401579, 1.0608877480343284]) \n",
      "25000: D: 0.6113422513008118/0.7780287861824036 G: 0.6537495255470276 \n",
      "(Real: [3.9573354488611221, 1.2388919910055891], Fake: [3.7122407233715058, 1.0583202437131141]) \n",
      "25200: D: 0.7383304834365845/0.6730595827102661 G: 0.767484724521637 \n",
      "(Real: [3.870515754111111, 1.3090404530631914], Fake: [4.7438565611839296, 0.99080340559031133]) \n",
      "25400: D: 0.6369554996490479/0.7526882290840149 G: 0.6810115575790405 \n",
      "(Real: [4.0165810388326646, 1.1305855660827797], Fake: [3.4167057454586027, 1.2535367359340253]) \n",
      "25600: D: 0.7152919173240662/0.6517302393913269 G: 0.6316124796867371 \n",
      "(Real: [3.9096024572849273, 1.2396668824550292], Fake: [4.0570248436927798, 1.1830362022817817]) \n",
      "25800: D: 0.799560010433197/0.6217488050460815 G: 0.7357656955718994 \n",
      "(Real: [3.874969265460968, 1.3563814131011673], Fake: [4.36414006114006, 1.2351672153606914]) \n",
      "26000: D: 0.5701327323913574/0.8360777497291565 G: 0.632575273513794 \n",
      "(Real: [3.8757610487937928, 1.2702609567615171], Fake: [3.6602990961074831, 1.1533601401281532]) \n",
      "26200: D: 0.7586451768875122/0.6600214242935181 G: 0.7603522539138794 \n",
      "(Real: [4.212895309925079, 1.1463337642018205], Fake: [4.5888179528713229, 1.2002367734308643]) \n",
      "26400: D: 0.6727211475372314/0.6813576817512512 G: 0.6760309934616089 \n",
      "(Real: [3.9460014390945433, 1.2844040893256978], Fake: [3.4594051992893218, 1.2899889761699068]) \n",
      "26600: D: 0.675848662853241/0.6506302356719971 G: 0.7579934000968933 \n",
      "(Real: [3.9227246642112732, 1.1993410071748345], Fake: [4.0853254330158233, 1.0719692265724068]) \n",
      "26800: D: 0.7696195244789124/0.6790783405303955 G: 0.7296903133392334 \n",
      "(Real: [4.0630348074436187, 1.2873398680472521], Fake: [4.3336801004409793, 1.1761383146561992]) \n",
      "27000: D: 0.7008786797523499/0.6747490763664246 G: 0.6306901574134827 \n",
      "(Real: [3.9591095501184466, 1.2995241162067812], Fake: [3.6055478435754775, 1.207987918858261]) \n",
      "27200: D: 0.8370099663734436/0.6051024794578552 G: 0.7401243448257446 \n",
      "(Real: [4.1528724747896195, 1.1957055949569269], Fake: [4.2826206409931187, 1.1818608162246587]) \n",
      "27400: D: 0.7776704430580139/0.7293028235435486 G: 0.576104998588562 \n",
      "(Real: [4.0819740456342695, 1.2637653562429836], Fake: [3.9598463916778566, 1.3104373749264806]) \n",
      "27600: D: 0.6734846234321594/0.8484750986099243 G: 0.6973283886909485 \n",
      "(Real: [4.1034724017977711, 1.1951012221501915], Fake: [3.5201788592338561, 1.3042894737229112]) \n",
      "27800: D: 0.6794236302375793/0.5665925741195679 G: 0.712534487247467 \n",
      "(Real: [4.0806939814239742, 1.302403910543769], Fake: [4.4770456016063687, 1.0949821660461949]) \n",
      "28000: D: 0.730989396572113/0.7647038698196411 G: 0.7852590680122375 \n",
      "(Real: [3.9102155745029448, 1.2000765054600764], Fake: [3.9325983119010925, 1.0845253240904529]) \n",
      "28200: D: 0.6055333018302917/0.6578335762023926 G: 0.6654036641120911 \n",
      "(Real: [4.0811389333009718, 1.2499485757913025], Fake: [3.7603530716896056, 1.1269850085385626]) \n",
      "28400: D: 0.6733465790748596/0.7161120176315308 G: 0.7277912497520447 \n",
      "(Real: [3.7796032226085661, 1.3087649036825688], Fake: [4.2477456951141361, 1.1340135295710183]) \n",
      "28600: D: 0.5519696474075317/0.7315481305122375 G: 0.6030958890914917 \n",
      "(Real: [4.0050811529159542, 1.1583494454454966], Fake: [3.7354117858409883, 1.2013240998534049]) \n",
      "28800: D: 0.6395356059074402/0.6154940724372864 G: 0.806185781955719 \n",
      "(Real: [4.0107644307613377, 1.3525954649199803], Fake: [4.2012844038009645, 1.3084047208936065]) \n",
      "29000: D: 0.628251850605011/0.7446386814117432 G: 0.5686804056167603 \n",
      "(Real: [3.9368503433465958, 1.3545702985524308], Fake: [3.8596354711055754, 1.1094993054558457]) \n",
      "29200: D: 0.7729133367538452/0.622035026550293 G: 0.6783474683761597 \n",
      "(Real: [4.215665783882141, 1.1491756131229292], Fake: [4.0224888086318966, 1.2232760678190344]) \n",
      "29400: D: 0.6622418761253357/0.6962175965309143 G: 0.7066286206245422 \n",
      "(Real: [4.1074246591329571, 1.2943148970868565], Fake: [4.0027501761913298, 1.2581148752455196]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29600: D: 0.6855615377426147/0.8035569190979004 G: 0.651859700679779 \n",
      "(Real: [4.1214955931901933, 1.2953032428029383], Fake: [4.0347378504276277, 1.1667436116449288]) \n",
      "29800: D: 0.6599339842796326/0.740149974822998 G: 0.6223009824752808 \n",
      "(Real: [3.8921004545688631, 1.2139082858719474], Fake: [4.2401549530029294, 1.234683474612206]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "        \n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s \\n(Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: visualize learning using matplotlib?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
