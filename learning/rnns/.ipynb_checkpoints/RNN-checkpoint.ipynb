{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "Ok, so I'm gonna try to make an RNN learn to speak like Hofstadter, trying to Google as little as possible :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD GEBB\n",
    "f = open(\"GEB.txt\",\"r\")\n",
    "lines = list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(filter(lambda x: x!= \"\\n\",lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contents \\n',\n",
       " 'Overview viii \\n',\n",
       " 'List of Illustrations xiv \\n',\n",
       " 'Words of Thanks xix \\n',\n",
       " 'Part I: GEB \\n',\n",
       " 'Introduction: A Musico-Logical Offering 3 \\n',\n",
       " 'Three-Part Invention 29 \\n',\n",
       " 'Chapter I: The MU-puzzle 33 \\n',\n",
       " 'Two-Part Invention 43 \\n',\n",
       " 'Chapter II: Meaning and Form in Mathematics 46 \\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [unicodeToAscii(l) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contents ',\n",
       " 'Overview viii ',\n",
       " 'List of Illustrations xiv ',\n",
       " 'Words of Thanks xix ',\n",
       " 'Part I GEB ',\n",
       " 'Introduction A Musico-Logical Offering  ',\n",
       " 'Three-Part Invention  ',\n",
       " 'Chapter I The MU-puzzle  ',\n",
       " 'Two-Part Invention  ',\n",
       " 'Chapter II Meaning and Form in Mathematics  ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_letters=len(all_letters)\n",
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line),1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "all_letters.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = inputTensor(lines[0])\n",
    "\n",
    "data = [inputTensor(l) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([81, 58])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1201].shape\n",
    "# torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [targetTensor(l) for l in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, how do I make an RNN? Hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2i = nn.Linear(input_size + hidden_size, input_size + hidden_size)\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        combined = F.relu(self.i2i(combined))\n",
    "        hidden = F.tanh(self.i2h(combined))\n",
    "        output = self.i2o(combined)\n",
    "        out = self.softmax(output)\n",
    "        logoutput = self.logsoftmax(output)\n",
    "        return logoutput, out, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "n = len(data)\n",
    "def get_minibatch(batch_size):\n",
    "    indices = random.sample(range(n),batch_size)\n",
    "    return [(data[i],targets[i]) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_minibatch(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_minibatch(10)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "h = Variable(torch.zeros(1,n_hidden))\n",
    "let = Variable(d[0,:,:])\n",
    "print(all_letters[torch.max(let,dim=1)[1]])\n",
    "lets = [let]\n",
    "for i in range(d.shape[0]):\n",
    "    loglet,let,h = rnn(let,h)\n",
    "    lets.append(let)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let.data.max(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an                                                                              '"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([all_letters[torch.max(let,dim=1)[1]] for let in lets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 58])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 14\n",
       " 13\n",
       " 19\n",
       "  4\n",
       " 13\n",
       " 19\n",
       " 18\n",
       " 52\n",
       " 57\n",
       "[torch.LongTensor of size 9]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "18273.955\n",
      "20\n",
      "197.85052\n",
      "40\n",
      "186.44801\n",
      "60\n",
      "206.44305\n",
      "80\n",
      "204.6592\n",
      "100\n",
      "184.1495\n",
      "120\n",
      "193.44643\n",
      "140\n",
      "185.58742\n",
      "160\n",
      "195.99701\n",
      "180\n",
      "179.80338\n",
      "200\n",
      "183.78091\n",
      "220\n",
      "212.04791\n",
      "240\n",
      "188.04787\n",
      "260\n",
      "193.50404\n",
      "280\n",
      "174.68011\n",
      "300\n",
      "179.58759\n",
      "320\n",
      "198.80202\n",
      "340\n",
      "179.47237\n",
      "360\n",
      "177.654\n",
      "380\n",
      "171.26312\n",
      "400\n",
      "196.1884\n",
      "420\n",
      "193.95432\n",
      "440\n",
      "186.82477\n",
      "460\n",
      "188.59761\n",
      "480\n",
      "183.27457\n",
      "500\n",
      "166.58975\n",
      "520\n",
      "192.50128\n",
      "540\n",
      "180.45566\n",
      "560\n",
      "192.27449\n",
      "580\n",
      "187.2057\n",
      "600\n",
      "171.79332\n",
      "620\n",
      "179.10445\n",
      "640\n",
      "175.2069\n",
      "660\n",
      "193.16768\n",
      "680\n",
      "177.98201\n",
      "700\n",
      "166.28717\n",
      "720\n",
      "186.90895\n",
      "740\n",
      "194.80846\n",
      "760\n",
      "189.47585\n",
      "780\n",
      "194.05463\n",
      "800\n",
      "158.87422\n"
     ]
    }
   ],
   "source": [
    "num_iters = 20000\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "for iteration in range(num_iters):\n",
    "    if iteration%(num_iters//1000)==0:\n",
    "        print(iteration)\n",
    "        print(loss.data.numpy()[0])\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "    for b in get_minibatch(batch_size):\n",
    "        d = b[0]\n",
    "        t = b[1]\n",
    "        h = Variable(torch.zeros(1,n_hidden))\n",
    "        for i in range(min(d.shape[0],100)):\n",
    "            loglet,let,h = rnn(Variable(d[i,:,:]),h)\n",
    "            loss += criterion(loglet,Variable(torch.LongTensor([t[i]])))\n",
    "    #         lets.append(let)\n",
    "    loss /= batch_size\n",
    "    loss.backward()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 191.1607\n",
       "[torch.FloatTensor of size (1,)]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets[0]\n",
    "let = Variable(d[0,:,:])\n",
    "h = Variable(torch.zeros(1,n_hidden))\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-17.0437\n",
       "[torch.FloatTensor of size (1,)]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for p in rnn.parameters():\n",
    "#     p.data.add_(-learning_rate, p.grad.data)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "let,h = rnn(let,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 5 \n",
       " -1.2321e+35 -2.0004e+35 -1.4388e+35 -1.6572e+35 -2.1657e+35 -1.4118e+35\n",
       " \n",
       " Columns 6 to 11 \n",
       " -5.8787e+34 -6.8438e+34 -4.8117e+34 -9.1716e+34 -1.1203e+35 -2.4750e+35\n",
       " \n",
       " Columns 12 to 17 \n",
       " -1.4414e+35 -1.7567e+35 -2.0139e+35 -2.3881e+35 -2.3693e+35 -1.6315e+35\n",
       " \n",
       " Columns 18 to 23 \n",
       " -1.6897e+35 -1.3693e+35 -2.2547e+35 -1.5294e+35 -6.9324e+34 -1.5436e+35\n",
       " \n",
       " Columns 24 to 29 \n",
       " -1.0741e+35 -1.5113e+35 -1.2160e+35 -3.0718e+35 -2.6615e+35 -1.4455e+35\n",
       " \n",
       " Columns 30 to 35 \n",
       " -1.3553e+35 -1.5185e+35 -1.5441e+35 -1.1154e+35 -7.4700e+34 -1.7922e+35\n",
       " \n",
       " Columns 36 to 41 \n",
       " -2.1953e+35 -7.7147e+34 -2.1341e+34 -6.6100e+34 -1.5884e+35 -1.4764e+35\n",
       " \n",
       " Columns 42 to 47 \n",
       " -2.3407e+35 -4.5978e+34 -1.1465e+35 -1.3441e+35 -2.0510e+35 -1.4557e+35\n",
       " \n",
       " Columns 48 to 53 \n",
       " -8.3190e+34 -2.0937e+35 -1.9348e+35 -2.0988e+35 -5.3290e+34  0.0000e+00\n",
       " \n",
       " Columns 54 to 57 \n",
       " -2.1335e+36 -1.2868e+35 -7.5572e+34 -1.5434e+35\n",
       " [torch.FloatTensor of size (1,58)], Variable containing:\n",
       " \n",
       " Columns 0 to 5 \n",
       "  7.4450e+34 -2.2198e+34  4.8984e+34 -6.2628e+34  9.1285e+34  1.3739e+35\n",
       " \n",
       " Columns 6 to 11 \n",
       "  8.9927e+34 -1.1093e+35  6.3355e+34  1.3793e+34 -1.1714e+35 -7.9961e+34\n",
       " \n",
       " Columns 12 to 17 \n",
       "  6.0876e+34  8.4307e+34  5.5972e+34 -1.3636e+35  8.1424e+34  4.2204e+33\n",
       " \n",
       " Columns 18 to 23 \n",
       "  1.2548e+35 -8.7147e+34  4.7174e+34  1.1953e+35 -5.6628e+34  6.0123e+34\n",
       " \n",
       " Columns 24 to 29 \n",
       "  1.6081e+34 -4.7517e+34  3.9932e+34  7.9178e+34 -4.1720e+34 -1.0437e+35\n",
       " \n",
       " Columns 30 to 35 \n",
       "  1.0304e+35 -7.3862e+33 -8.4964e+34  4.6305e+34  4.5291e+34 -1.3741e+35\n",
       " \n",
       " Columns 36 to 41 \n",
       " -6.2880e+33  6.6931e+34  5.0052e+34  1.6364e+35 -5.3423e+34  3.9937e+34\n",
       " \n",
       " Columns 42 to 47 \n",
       " -5.3941e+34 -8.1411e+34  7.3561e+34  2.0456e+32  2.9069e+34 -9.0061e+34\n",
       " \n",
       " Columns 48 to 53 \n",
       "  1.3654e+35 -1.2224e+35  8.8365e+34  3.8022e+34  5.1280e+34  5.2047e+34\n",
       " \n",
       " Columns 54 to 59 \n",
       " -1.1253e+35 -5.3171e+34  5.6895e+33 -1.0938e+35  3.3569e+34  6.0487e+34\n",
       " \n",
       " Columns 60 to 65 \n",
       "  1.2247e+35  1.9433e+35  5.7360e+34 -3.4503e+34  1.6484e+34 -7.2579e+34\n",
       " \n",
       " Columns 66 to 71 \n",
       " -8.9639e+34  1.1215e+34 -1.1504e+35  1.1718e+35  9.4688e+34 -1.7903e+34\n",
       " \n",
       " Columns 72 to 77 \n",
       " -1.8837e+35  5.6684e+34 -1.7593e+33 -8.5523e+34  8.4619e+34  4.1068e+33\n",
       " \n",
       " Columns 78 to 83 \n",
       " -8.8065e+34 -1.2745e+35 -8.0917e+34  1.1790e+35  1.7714e+34  6.0129e+34\n",
       " \n",
       " Columns 84 to 89 \n",
       " -1.0791e+35  9.8657e+34  3.5132e+34  4.4944e+34  8.1871e+34  6.7850e+34\n",
       " \n",
       " Columns 90 to 95 \n",
       "  9.7847e+34  2.8692e+34  4.2001e+32  5.0792e+33 -5.0024e+34  7.0327e+34\n",
       " \n",
       " Columns 96 to 101 \n",
       " -6.7428e+34 -1.2715e+35 -1.4236e+35 -9.4052e+34 -8.2304e+34 -1.1397e+35\n",
       " \n",
       " Columns 102 to 107 \n",
       " -2.8584e+34 -1.9923e+34  7.6713e+34  3.2564e+34  1.7229e+34 -3.9545e+34\n",
       " \n",
       " Columns 108 to 113 \n",
       "  8.7537e+34 -6.0894e+34  5.1275e+34  4.7691e+34 -8.1900e+34 -2.3404e+34\n",
       " \n",
       " Columns 114 to 119 \n",
       " -1.0917e+34  8.4182e+34  5.8388e+32 -2.1465e+34 -7.6868e+34  1.0428e+35\n",
       " \n",
       " Columns 120 to 125 \n",
       " -5.8874e+34 -5.9979e+34 -6.2510e+34  1.3793e+35 -4.0212e+34  1.6639e+35\n",
       " \n",
       " Columns 126 to 127 \n",
       " -2.3221e+34 -3.3158e+34\n",
       " [torch.FloatTensor of size (1,128)])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
